Inizio training IRL
Using device: cuda
Using cuda device
=== Iterazione IRL 0 ===
Loss reward (iter 0): 6.918726921081543
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 248      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -1.11    |
|    critic_loss     | 0.00201  |
|    learning_rate   | 0.001    |
|    n_updates       | 299      |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 220      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | -1.73    |
|    critic_loss     | 0.00447  |
|    learning_rate   | 0.001    |
|    n_updates       | 699      |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 212      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | -2.21    |
|    critic_loss     | 0.00634  |
|    learning_rate   | 0.001    |
|    n_updates       | 1099     |
---------------------------------
=== Iterazione IRL 1 ===
Loss reward (iter 1): 7.008495330810547
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -2.78    |
|    critic_loss     | 0.115    |
|    learning_rate   | 0.001    |
|    n_updates       | 1699     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | -2.92    |
|    critic_loss     | 0.155    |
|    learning_rate   | 0.001    |
|    n_updates       | 2099     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | -3.14    |
|    critic_loss     | 0.157    |
|    learning_rate   | 0.001    |
|    n_updates       | 2499     |
---------------------------------
=== Iterazione IRL 2 ===
Loss reward (iter 2): 6.115211486816406
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -3.19    |
|    critic_loss     | 0.28     |
|    learning_rate   | 0.001    |
|    n_updates       | 3099     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | -3.01    |
|    critic_loss     | 0.567    |
|    learning_rate   | 0.001    |
|    n_updates       | 3499     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | -3.14    |
|    critic_loss     | 0.694    |
|    learning_rate   | 0.001    |
|    n_updates       | 3899     |
---------------------------------
=== Iterazione IRL 3 ===
Loss reward (iter 3): 5.175703048706055
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 271      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -2.39    |
|    critic_loss     | 1.02     |
|    learning_rate   | 0.001    |
|    n_updates       | 4499     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 238      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | -1.91    |
|    critic_loss     | 1.1      |
|    learning_rate   | 0.001    |
|    n_updates       | 4899     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | -1.43    |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.001    |
|    n_updates       | 5299     |
---------------------------------
=== Iterazione IRL 4 ===
Loss reward (iter 4): 4.211881637573242
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 271      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -0.482   |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.001    |
|    n_updates       | 5899     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 238      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 0.447    |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.001    |
|    n_updates       | 6299     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 224      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.63     |
|    critic_loss     | 2.64     |
|    learning_rate   | 0.001    |
|    n_updates       | 6699     |
---------------------------------
=== Iterazione IRL 5 ===
Loss reward (iter 5): 3.159374713897705
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.1      |
|    critic_loss     | 2.96     |
|    learning_rate   | 0.001    |
|    n_updates       | 7299     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.83     |
|    critic_loss     | 2.99     |
|    learning_rate   | 0.001    |
|    n_updates       | 7699     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 5.85     |
|    critic_loss     | 3.46     |
|    learning_rate   | 0.001    |
|    n_updates       | 8099     |
---------------------------------
=== Iterazione IRL 6 ===
Loss reward (iter 6): 1.8248711824417114
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 8.39     |
|    critic_loss     | 4.29     |
|    learning_rate   | 0.001    |
|    n_updates       | 8699     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 9.92     |
|    critic_loss     | 5.19     |
|    learning_rate   | 0.001    |
|    n_updates       | 9099     |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 12.8     |
|    critic_loss     | 4.77     |
|    learning_rate   | 0.001    |
|    n_updates       | 9499     |
---------------------------------
=== Iterazione IRL 7 ===
Loss reward (iter 7): 0.1851583570241928
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 15.8     |
|    critic_loss     | 7.35     |
|    learning_rate   | 0.001    |
|    n_updates       | 10099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 16.8     |
|    critic_loss     | 7.82     |
|    learning_rate   | 0.001    |
|    n_updates       | 10499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 19.7     |
|    critic_loss     | 11.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 10899    |
---------------------------------
=== Iterazione IRL 8 ===
Loss reward (iter 8): -1.717310905456543
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 23.9     |
|    critic_loss     | 11.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 11499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 26.4     |
|    critic_loss     | 14.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 11899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 28.9     |
|    critic_loss     | 17.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 12299    |
---------------------------------
=== Iterazione IRL 9 ===
Loss reward (iter 9): -3.9117848873138428
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 34       |
|    critic_loss     | 23.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 12899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 36.2     |
|    critic_loss     | 23.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 13299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 40.1     |
|    critic_loss     | 24       |
|    learning_rate   | 0.001    |
|    n_updates       | 13699    |
---------------------------------
=== Iterazione IRL 10 ===
Loss reward (iter 10): -6.525276184082031
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 269      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 45.7     |
|    critic_loss     | 31.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 14299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 236      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 48.2     |
|    critic_loss     | 34.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 14699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 223      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 53.5     |
|    critic_loss     | 35.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 15099    |
---------------------------------
=== Iterazione IRL 11 ===
Loss reward (iter 11): -9.774948120117188
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 58.8     |
|    critic_loss     | 50.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 15699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 63       |
|    critic_loss     | 49.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 16099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 64.5     |
|    critic_loss     | 63.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 16499    |
---------------------------------
=== Iterazione IRL 12 ===
Loss reward (iter 12): -13.338088989257812
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 73.6     |
|    critic_loss     | 61.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 17099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 226      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 77.6     |
|    critic_loss     | 81.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 17499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 221      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 83.4     |
|    critic_loss     | 97       |
|    learning_rate   | 0.001    |
|    n_updates       | 17899    |
---------------------------------
=== Iterazione IRL 13 ===
Loss reward (iter 13): -17.346166610717773
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 92.9     |
|    critic_loss     | 111      |
|    learning_rate   | 0.001    |
|    n_updates       | 18499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 94.9     |
|    critic_loss     | 109      |
|    learning_rate   | 0.001    |
|    n_updates       | 18899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 104      |
|    critic_loss     | 130      |
|    learning_rate   | 0.001    |
|    n_updates       | 19299    |
---------------------------------
=== Iterazione IRL 14 ===
Loss reward (iter 14): -22.512311935424805
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 110      |
|    critic_loss     | 139      |
|    learning_rate   | 0.001    |
|    n_updates       | 19899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 115      |
|    critic_loss     | 193      |
|    learning_rate   | 0.001    |
|    n_updates       | 20299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 227      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 124      |
|    critic_loss     | 165      |
|    learning_rate   | 0.001    |
|    n_updates       | 20699    |
---------------------------------
=== Iterazione IRL 15 ===
Loss reward (iter 15): -27.95792007446289
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 135      |
|    critic_loss     | 231      |
|    learning_rate   | 0.001    |
|    n_updates       | 21299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 138      |
|    critic_loss     | 219      |
|    learning_rate   | 0.001    |
|    n_updates       | 21699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 147      |
|    critic_loss     | 205      |
|    learning_rate   | 0.001    |
|    n_updates       | 22099    |
---------------------------------
=== Iterazione IRL 16 ===
Loss reward (iter 16): -33.4412727355957
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 160      |
|    critic_loss     | 305      |
|    learning_rate   | 0.001    |
|    n_updates       | 22699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 166      |
|    critic_loss     | 241      |
|    learning_rate   | 0.001    |
|    n_updates       | 23099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 172      |
|    critic_loss     | 416      |
|    learning_rate   | 0.001    |
|    n_updates       | 23499    |
---------------------------------
=== Iterazione IRL 17 ===
Loss reward (iter 17): -40.87248611450195
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 188      |
|    critic_loss     | 377      |
|    learning_rate   | 0.001    |
|    n_updates       | 24099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 196      |
|    critic_loss     | 429      |
|    learning_rate   | 0.001    |
|    n_updates       | 24499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 202      |
|    critic_loss     | 458      |
|    learning_rate   | 0.001    |
|    n_updates       | 24899    |
---------------------------------
=== Iterazione IRL 18 ===
Loss reward (iter 18): -48.512535095214844
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 221      |
|    critic_loss     | 510      |
|    learning_rate   | 0.001    |
|    n_updates       | 25499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 226      |
|    critic_loss     | 483      |
|    learning_rate   | 0.001    |
|    n_updates       | 25899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 240      |
|    critic_loss     | 551      |
|    learning_rate   | 0.001    |
|    n_updates       | 26299    |
---------------------------------
=== Iterazione IRL 19 ===
Loss reward (iter 19): -56.78300094604492
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 253      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 256      |
|    critic_loss     | 631      |
|    learning_rate   | 0.001    |
|    n_updates       | 26899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 266      |
|    critic_loss     | 733      |
|    learning_rate   | 0.001    |
|    n_updates       | 27299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 276      |
|    critic_loss     | 762      |
|    learning_rate   | 0.001    |
|    n_updates       | 27699    |
---------------------------------
=== Iterazione IRL 20 ===
Loss reward (iter 20): -65.79906463623047
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 292      |
|    critic_loss     | 1.19e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 28299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 316      |
|    critic_loss     | 910      |
|    learning_rate   | 0.001    |
|    n_updates       | 28699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 323      |
|    critic_loss     | 960      |
|    learning_rate   | 0.001    |
|    n_updates       | 29099    |
---------------------------------
=== Iterazione IRL 21 ===
Loss reward (iter 21): -75.47858428955078
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 350      |
|    critic_loss     | 1.21e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 29699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 363      |
|    critic_loss     | 1.38e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 30099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 363      |
|    critic_loss     | 1.53e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 30499    |
---------------------------------
=== Iterazione IRL 22 ===
Loss reward (iter 22): -86.77192687988281
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 395      |
|    critic_loss     | 1.61e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 31099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 405      |
|    critic_loss     | 1.98e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 31499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 433      |
|    critic_loss     | 1.74e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 31899    |
---------------------------------
=== Iterazione IRL 23 ===
Loss reward (iter 23): -99.22128295898438
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 253      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 461      |
|    critic_loss     | 1.86e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 32499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 480      |
|    critic_loss     | 1.89e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 32899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 493      |
|    critic_loss     | 2.37e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 33299    |
---------------------------------
=== Iterazione IRL 24 ===
Loss reward (iter 24): -111.60238647460938
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 253      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 521      |
|    critic_loss     | 2.14e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 33899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 553      |
|    critic_loss     | 2.34e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 34299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 575      |
|    critic_loss     | 2.36e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 34699    |
---------------------------------
=== Iterazione IRL 25 ===
Loss reward (iter 25): -125.74918365478516
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 253      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 605      |
|    critic_loss     | 3.1e+03  |
|    learning_rate   | 0.001    |
|    n_updates       | 35299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 649      |
|    critic_loss     | 3.04e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 35699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 659      |
|    critic_loss     | 2.85e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 36099    |
---------------------------------
=== Iterazione IRL 26 ===
Loss reward (iter 26): -140.50027465820312
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 263      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 688      |
|    critic_loss     | 2.5e+03  |
|    learning_rate   | 0.001    |
|    n_updates       | 36699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 234      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 724      |
|    critic_loss     | 3.08e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 37099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 225      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 764      |
|    critic_loss     | 3.71e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 37499    |
---------------------------------
=== Iterazione IRL 27 ===
Loss reward (iter 27): -158.96438598632812
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 780      |
|    critic_loss     | 3.66e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 38099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 823      |
|    critic_loss     | 4.71e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 38499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 829      |
|    critic_loss     | 4.57e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 38899    |
---------------------------------
=== Iterazione IRL 28 ===
Loss reward (iter 28): -175.48623657226562
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 878      |
|    critic_loss     | 4.06e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 39499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 924      |
|    critic_loss     | 5.96e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 39899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 943      |
|    critic_loss     | 5.33e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 40299    |
---------------------------------
=== Iterazione IRL 29 ===
Loss reward (iter 29): -198.70635986328125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.01e+03 |
|    critic_loss     | 6.72e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 40899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.02e+03 |
|    critic_loss     | 6.28e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 41299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.07e+03 |
|    critic_loss     | 5.71e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 41699    |
---------------------------------
=== Iterazione IRL 30 ===
Loss reward (iter 30): -217.93319702148438
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.16e+03 |
|    critic_loss     | 7.02e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 42299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.15e+03 |
|    critic_loss     | 8.04e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 42699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.18e+03 |
|    critic_loss     | 6.59e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 43099    |
---------------------------------
=== Iterazione IRL 31 ===
Loss reward (iter 31): -241.0233154296875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.26e+03 |
|    critic_loss     | 6.78e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 43699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.28e+03 |
|    critic_loss     | 9.17e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 44099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.37e+03 |
|    critic_loss     | 9.93e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 44499    |
---------------------------------
=== Iterazione IRL 32 ===
Loss reward (iter 32): -267.7371826171875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.38e+03 |
|    critic_loss     | 1.03e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 45099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.45e+03 |
|    critic_loss     | 1.07e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 45499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.5e+03  |
|    critic_loss     | 1.22e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 45899    |
---------------------------------
=== Iterazione IRL 33 ===
Loss reward (iter 33): -295.2000732421875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.56e+03 |
|    critic_loss     | 1.21e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 46499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.62e+03 |
|    critic_loss     | 1.19e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 46899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.67e+03 |
|    critic_loss     | 1.41e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 47299    |
---------------------------------
=== Iterazione IRL 34 ===
Loss reward (iter 34): -325.7112121582031
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.73e+03 |
|    critic_loss     | 1.13e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 47899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 232      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.79e+03 |
|    critic_loss     | 1.48e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 48299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 222      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.87e+03 |
|    critic_loss     | 1.36e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 48699    |
---------------------------------
=== Iterazione IRL 35 ===
Loss reward (iter 35): -356.8536071777344
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.94e+03 |
|    critic_loss     | 1.61e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 49299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.02e+03 |
|    critic_loss     | 1.68e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 49699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.04e+03 |
|    critic_loss     | 1.55e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 50099    |
---------------------------------
=== Iterazione IRL 36 ===
Loss reward (iter 36): -390.4410400390625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.14e+03 |
|    critic_loss     | 1.67e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 50699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.17e+03 |
|    critic_loss     | 2.11e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 51099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.31e+03 |
|    critic_loss     | 2.11e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 51499    |
---------------------------------
=== Iterazione IRL 37 ===
Loss reward (iter 37): -422.8662414550781
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.36e+03 |
|    critic_loss     | 2.52e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 52099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.46e+03 |
|    critic_loss     | 2.27e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 52499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 227      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.49e+03 |
|    critic_loss     | 2.41e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 52899    |
---------------------------------
=== Iterazione IRL 38 ===
Loss reward (iter 38): -460.6834411621094
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 269      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.57e+03 |
|    critic_loss     | 2.76e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 53499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 236      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.69e+03 |
|    critic_loss     | 2.45e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 53899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 227      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.75e+03 |
|    critic_loss     | 2.87e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 54299    |
---------------------------------
=== Iterazione IRL 39 ===
Loss reward (iter 39): -501.2205810546875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.86e+03 |
|    critic_loss     | 2.7e+04  |
|    learning_rate   | 0.001    |
|    n_updates       | 54899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.97e+03 |
|    critic_loss     | 3.62e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 55299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.01e+03 |
|    critic_loss     | 3.2e+04  |
|    learning_rate   | 0.001    |
|    n_updates       | 55699    |
---------------------------------
=== Iterazione IRL 40 ===
Loss reward (iter 40): -544.974853515625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.09e+03 |
|    critic_loss     | 3.45e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 56299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.19e+03 |
|    critic_loss     | 3.31e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 56699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.22e+03 |
|    critic_loss     | 3.56e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 57099    |
---------------------------------
=== Iterazione IRL 41 ===
Loss reward (iter 41): -587.2618408203125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.36e+03 |
|    critic_loss     | 4.81e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 57699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.49e+03 |
|    critic_loss     | 4.33e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 58099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.53e+03 |
|    critic_loss     | 4.79e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 58499    |
---------------------------------
=== Iterazione IRL 42 ===
Loss reward (iter 42): -632.33203125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.69e+03 |
|    critic_loss     | 4.86e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 59099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 231      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.8e+03  |
|    critic_loss     | 4.88e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 59499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 220      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.89e+03 |
|    critic_loss     | 5.52e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 59899    |
---------------------------------
=== Iterazione IRL 43 ===
Loss reward (iter 43): -683.2513427734375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.97e+03 |
|    critic_loss     | 5.04e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 60499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.11e+03 |
|    critic_loss     | 5.27e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 60899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.22e+03 |
|    critic_loss     | 6.44e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 61299    |
---------------------------------
=== Iterazione IRL 44 ===
Loss reward (iter 44): -739.5018310546875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 4.36e+03 |
|    critic_loss     | 6.33e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 61899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.47e+03 |
|    critic_loss     | 7.32e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 62299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.64e+03 |
|    critic_loss     | 7.83e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 62699    |
---------------------------------
=== Iterazione IRL 45 ===
Loss reward (iter 45): -794.0552978515625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 4.77e+03 |
|    critic_loss     | 7.93e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 63299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.86e+03 |
|    critic_loss     | 7.15e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 63699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.94e+03 |
|    critic_loss     | 7.55e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 64099    |
---------------------------------
=== Iterazione IRL 46 ===
Loss reward (iter 46): -853.8829956054688
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 5.11e+03 |
|    critic_loss     | 9.27e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 64699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 5.23e+03 |
|    critic_loss     | 1.01e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 65099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 5.4e+03  |
|    critic_loss     | 9.04e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 65499    |
---------------------------------
=== Iterazione IRL 47 ===
Loss reward (iter 47): -912.4131469726562
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 5.61e+03 |
|    critic_loss     | 8.66e+04 |
|    learning_rate   | 0.001    |
|    n_updates       | 66099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 5.72e+03 |
|    critic_loss     | 1.09e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 66499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 5.84e+03 |
|    critic_loss     | 1.16e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 66899    |
---------------------------------
=== Iterazione IRL 48 ===
Loss reward (iter 48): -980.4879150390625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 6.11e+03 |
|    critic_loss     | 1.11e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 67499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 6.1e+03  |
|    critic_loss     | 1.25e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 67899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 6.32e+03 |
|    critic_loss     | 1.34e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 68299    |
---------------------------------
=== Iterazione IRL 49 ===
Loss reward (iter 49): -1039.5318603515625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 6.58e+03 |
|    critic_loss     | 1.23e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 68899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 6.7e+03  |
|    critic_loss     | 1.32e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 69299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 6.8e+03  |
|    critic_loss     | 1.27e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 69699    |
---------------------------------
=== Iterazione IRL 50 ===
Loss reward (iter 50): -1116.8358154296875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 271      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 6.98e+03 |
|    critic_loss     | 1.3e+05  |
|    learning_rate   | 0.001    |
|    n_updates       | 70299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 7.23e+03 |
|    critic_loss     | 1.57e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 70699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 7.38e+03 |
|    critic_loss     | 1.41e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 71099    |
---------------------------------
=== Iterazione IRL 51 ===
Loss reward (iter 51): -1188.0091552734375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 7.57e+03 |
|    critic_loss     | 1.47e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 71699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 7.91e+03 |
|    critic_loss     | 1.63e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 72099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 7.97e+03 |
|    critic_loss     | 1.97e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 72499    |
---------------------------------
=== Iterazione IRL 52 ===
Loss reward (iter 52): -1265.7215576171875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 8.28e+03 |
|    critic_loss     | 2.08e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 73099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 8.58e+03 |
|    critic_loss     | 1.91e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 73499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 8.7e+03  |
|    critic_loss     | 2.08e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 73899    |
---------------------------------
=== Iterazione IRL 53 ===
Loss reward (iter 53): -1336.6688232421875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 8.92e+03 |
|    critic_loss     | 2.29e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 74499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 9.13e+03 |
|    critic_loss     | 2.61e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 74899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 9.24e+03 |
|    critic_loss     | 2.22e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 75299    |
---------------------------------
=== Iterazione IRL 54 ===
Loss reward (iter 54): -1441.6363525390625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 9.59e+03 |
|    critic_loss     | 2.87e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 75899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 9.68e+03 |
|    critic_loss     | 2.62e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 76299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 9.99e+03 |
|    critic_loss     | 2.59e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 76699    |
---------------------------------
=== Iterazione IRL 55 ===
Loss reward (iter 55): -1525.7626953125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.03e+04 |
|    critic_loss     | 3e+05    |
|    learning_rate   | 0.001    |
|    n_updates       | 77299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.05e+04 |
|    critic_loss     | 2.91e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 77699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.07e+04 |
|    critic_loss     | 2.44e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 78099    |
---------------------------------
=== Iterazione IRL 56 ===
Loss reward (iter 56): -1611.18505859375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.11e+04 |
|    critic_loss     | 2.92e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 78699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.13e+04 |
|    critic_loss     | 3.03e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 79099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.14e+04 |
|    critic_loss     | 2.98e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 79499    |
---------------------------------
=== Iterazione IRL 57 ===
Loss reward (iter 57): -1678.2470703125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.17e+04 |
|    critic_loss     | 3.68e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 80099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.2e+04  |
|    critic_loss     | 3.54e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 80499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.23e+04 |
|    critic_loss     | 3.19e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 80899    |
---------------------------------
=== Iterazione IRL 58 ===
Loss reward (iter 58): -1808.4854736328125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.27e+04 |
|    critic_loss     | 3.67e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 81499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.29e+04 |
|    critic_loss     | 4.54e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 81899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.32e+04 |
|    critic_loss     | 4.27e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 82299    |
---------------------------------
=== Iterazione IRL 59 ===
Loss reward (iter 59): -1879.5404052734375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.35e+04 |
|    critic_loss     | 3.75e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 82899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.38e+04 |
|    critic_loss     | 4.22e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 83299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.4e+04  |
|    critic_loss     | 4.36e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 83699    |
---------------------------------
=== Iterazione IRL 60 ===
Loss reward (iter 60): -1999.1676025390625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.42e+04 |
|    critic_loss     | 5.62e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 84299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.46e+04 |
|    critic_loss     | 5.11e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 84699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.51e+04 |
|    critic_loss     | 5.9e+05  |
|    learning_rate   | 0.001    |
|    n_updates       | 85099    |
---------------------------------
=== Iterazione IRL 61 ===
Loss reward (iter 61): -2107.958740234375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.53e+04 |
|    critic_loss     | 5.29e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 85699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.57e+04 |
|    critic_loss     | 5.83e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 86099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.59e+04 |
|    critic_loss     | 4.8e+05  |
|    learning_rate   | 0.001    |
|    n_updates       | 86499    |
---------------------------------
=== Iterazione IRL 62 ===
Loss reward (iter 62): -2236.7265625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.66e+04 |
|    critic_loss     | 5.69e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 87099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.65e+04 |
|    critic_loss     | 6e+05    |
|    learning_rate   | 0.001    |
|    n_updates       | 87499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.7e+04  |
|    critic_loss     | 6.99e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 87899    |
---------------------------------
=== Iterazione IRL 63 ===
Loss reward (iter 63): -2350.576904296875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 253      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.75e+04 |
|    critic_loss     | 7.02e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 88499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 222      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.76e+04 |
|    critic_loss     | 6.68e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 88899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 213      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.8e+04  |
|    critic_loss     | 7.11e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 89299    |
---------------------------------
=== Iterazione IRL 64 ===
Loss reward (iter 64): -2467.410400390625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.84e+04 |
|    critic_loss     | 7.29e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 89899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.89e+04 |
|    critic_loss     | 8.41e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 90299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.91e+04 |
|    critic_loss     | 8.17e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 90699    |
---------------------------------
=== Iterazione IRL 65 ===
Loss reward (iter 65): -2605.420166015625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.98e+04 |
|    critic_loss     | 7.28e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 91299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.98e+04 |
|    critic_loss     | 8.7e+05  |
|    learning_rate   | 0.001    |
|    n_updates       | 91699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2e+04    |
|    critic_loss     | 7.04e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 92099    |
---------------------------------
=== Iterazione IRL 66 ===
Loss reward (iter 66): -2729.37548828125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.11e+04 |
|    critic_loss     | 9.07e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 92699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.12e+04 |
|    critic_loss     | 9.53e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 93099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.14e+04 |
|    critic_loss     | 1.01e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 93499    |
---------------------------------
=== Iterazione IRL 67 ===
Loss reward (iter 67): -2875.216552734375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.16e+04 |
|    critic_loss     | 9.94e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 94099    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.23e+04 |
|    critic_loss     | 9.18e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 94499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.29e+04 |
|    critic_loss     | 1.01e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 94899    |
---------------------------------
=== Iterazione IRL 68 ===
Loss reward (iter 68): -2984.206787109375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.35e+04 |
|    critic_loss     | 1.24e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 95499    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.36e+04 |
|    critic_loss     | 1.19e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 95899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.38e+04 |
|    critic_loss     | 9.97e+05 |
|    learning_rate   | 0.001    |
|    n_updates       | 96299    |
---------------------------------
=== Iterazione IRL 69 ===
Loss reward (iter 69): -3146.520751953125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.49e+04 |
|    critic_loss     | 1.1e+06  |
|    learning_rate   | 0.001    |
|    n_updates       | 96899    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.51e+04 |
|    critic_loss     | 1.11e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 97299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.58e+04 |
|    critic_loss     | 1.12e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 97699    |
---------------------------------
=== Iterazione IRL 70 ===
Loss reward (iter 70): -3244.2919921875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.59e+04 |
|    critic_loss     | 1.33e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 98299    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.65e+04 |
|    critic_loss     | 1.23e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 98699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.68e+04 |
|    critic_loss     | 1.34e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 99099    |
---------------------------------
=== Iterazione IRL 71 ===
Loss reward (iter 71): -3445.1923828125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 256      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.77e+04 |
|    critic_loss     | 1.4e+06  |
|    learning_rate   | 0.001    |
|    n_updates       | 99699    |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.81e+04 |
|    critic_loss     | 1.52e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 100099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.82e+04 |
|    critic_loss     | 1.46e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 100499   |
---------------------------------
=== Iterazione IRL 72 ===
Loss reward (iter 72): -3660.161376953125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 254      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 2.88e+04 |
|    critic_loss     | 1.64e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 101099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 2.92e+04 |
|    critic_loss     | 1.7e+06  |
|    learning_rate   | 0.001    |
|    n_updates       | 101499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 2.98e+04 |
|    critic_loss     | 1.75e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 101899   |
---------------------------------
=== Iterazione IRL 73 ===
Loss reward (iter 73): -3708.726806640625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 256      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.04e+04 |
|    critic_loss     | 1.86e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 102499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.1e+04  |
|    critic_loss     | 1.64e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 102899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.11e+04 |
|    critic_loss     | 1.75e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 103299   |
---------------------------------
=== Iterazione IRL 74 ===
Loss reward (iter 74): -3953.92138671875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 256      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.19e+04 |
|    critic_loss     | 1.88e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 103899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.26e+04 |
|    critic_loss     | 2.12e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 104299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.29e+04 |
|    critic_loss     | 1.67e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 104699   |
---------------------------------
=== Iterazione IRL 75 ===
Loss reward (iter 75): -4078.884033203125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 256      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.34e+04 |
|    critic_loss     | 1.78e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 105299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.44e+04 |
|    critic_loss     | 2.35e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 105699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 221      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.43e+04 |
|    critic_loss     | 2.3e+06  |
|    learning_rate   | 0.001    |
|    n_updates       | 106099   |
---------------------------------
=== Iterazione IRL 76 ===
Loss reward (iter 76): -4291.1669921875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.53e+04 |
|    critic_loss     | 2.26e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 106699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.53e+04 |
|    critic_loss     | 2.33e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 107099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.62e+04 |
|    critic_loss     | 2.16e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 107499   |
---------------------------------
=== Iterazione IRL 77 ===
Loss reward (iter 77): -4424.24609375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.74e+04 |
|    critic_loss     | 2.51e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 108099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.74e+04 |
|    critic_loss     | 2.26e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 108499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.76e+04 |
|    critic_loss     | 2.48e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 108899   |
---------------------------------
=== Iterazione IRL 78 ===
Loss reward (iter 78): -4690.25048828125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 3.84e+04 |
|    critic_loss     | 2.87e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 109499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 3.9e+04  |
|    critic_loss     | 2.91e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 109899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 3.98e+04 |
|    critic_loss     | 2.34e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 110299   |
---------------------------------
=== Iterazione IRL 79 ===
Loss reward (iter 79): -4885.6826171875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 4.05e+04 |
|    critic_loss     | 2.36e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 110899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.11e+04 |
|    critic_loss     | 3.04e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 111299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.17e+04 |
|    critic_loss     | 3.05e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 111699   |
---------------------------------
=== Iterazione IRL 80 ===
Loss reward (iter 80): -5035.2578125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 4.23e+04 |
|    critic_loss     | 3.12e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 112299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.25e+04 |
|    critic_loss     | 2.41e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 112699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.35e+04 |
|    critic_loss     | 3.06e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 113099   |
---------------------------------
=== Iterazione IRL 81 ===
Loss reward (iter 81): -5246.51318359375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 4.38e+04 |
|    critic_loss     | 4e+06    |
|    learning_rate   | 0.001    |
|    n_updates       | 113699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 238      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.51e+04 |
|    critic_loss     | 3.86e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 114099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 224      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.56e+04 |
|    critic_loss     | 3.6e+06  |
|    learning_rate   | 0.001    |
|    n_updates       | 114499   |
---------------------------------
=== Iterazione IRL 82 ===
Loss reward (iter 82): -5449.54150390625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 4.68e+04 |
|    critic_loss     | 4.16e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 115099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.7e+04  |
|    critic_loss     | 3.76e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 115499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.73e+04 |
|    critic_loss     | 3.58e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 115899   |
---------------------------------
=== Iterazione IRL 83 ===
Loss reward (iter 83): -5611.2392578125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 4.85e+04 |
|    critic_loss     | 3.73e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 116499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 4.9e+04  |
|    critic_loss     | 4.58e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 116899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 4.95e+04 |
|    critic_loss     | 4.39e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 117299   |
---------------------------------
=== Iterazione IRL 84 ===
Loss reward (iter 84): -5914.208984375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 5.04e+04 |
|    critic_loss     | 3.86e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 117899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 5.14e+04 |
|    critic_loss     | 4.36e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 118299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 5.15e+04 |
|    critic_loss     | 5.02e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 118699   |
---------------------------------
=== Iterazione IRL 85 ===
Loss reward (iter 85): -6097.58837890625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 5.21e+04 |
|    critic_loss     | 3.94e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 119299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 5.31e+04 |
|    critic_loss     | 4.99e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 119699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 5.41e+04 |
|    critic_loss     | 4.06e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 120099   |
---------------------------------
=== Iterazione IRL 86 ===
Loss reward (iter 86): -6335.90185546875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 5.46e+04 |
|    critic_loss     | 5.48e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 120699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 5.49e+04 |
|    critic_loss     | 5.38e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 121099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 5.62e+04 |
|    critic_loss     | 4.77e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 121499   |
---------------------------------
=== Iterazione IRL 87 ===
Loss reward (iter 87): -6591.02734375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 5.61e+04 |
|    critic_loss     | 5.1e+06  |
|    learning_rate   | 0.001    |
|    n_updates       | 122099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 5.81e+04 |
|    critic_loss     | 5.81e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 122499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 217      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 5.86e+04 |
|    critic_loss     | 5.42e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 122899   |
---------------------------------
=== Iterazione IRL 88 ===
Loss reward (iter 88): -6810.896484375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 6e+04    |
|    critic_loss     | 6.66e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 123499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 5.97e+04 |
|    critic_loss     | 6.25e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 123899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 6.03e+04 |
|    critic_loss     | 6.3e+06  |
|    learning_rate   | 0.001    |
|    n_updates       | 124299   |
---------------------------------
=== Iterazione IRL 89 ===
Loss reward (iter 89): -7043.857421875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 6.15e+04 |
|    critic_loss     | 5.29e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 124899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 6.29e+04 |
|    critic_loss     | 5.89e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 125299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 6.39e+04 |
|    critic_loss     | 6.14e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 125699   |
---------------------------------
=== Iterazione IRL 90 ===
Loss reward (iter 90): -7270.33447265625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 6.52e+04 |
|    critic_loss     | 7.48e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 126299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 6.5e+04  |
|    critic_loss     | 5.97e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 126699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 6.56e+04 |
|    critic_loss     | 7.42e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 127099   |
---------------------------------
=== Iterazione IRL 91 ===
Loss reward (iter 91): -7576.20458984375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 6.67e+04 |
|    critic_loss     | 7.31e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 127699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 6.81e+04 |
|    critic_loss     | 7.55e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 128099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 6.85e+04 |
|    critic_loss     | 7.34e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 128499   |
---------------------------------
=== Iterazione IRL 92 ===
Loss reward (iter 92): -7884.5712890625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 7.02e+04 |
|    critic_loss     | 8.37e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 129099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 6.97e+04 |
|    critic_loss     | 7.31e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 129499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 229      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 7.22e+04 |
|    critic_loss     | 8.92e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 129899   |
---------------------------------
=== Iterazione IRL 93 ===
Loss reward (iter 93): -8132.42822265625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 7.24e+04 |
|    critic_loss     | 7.75e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 130499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 7.3e+04  |
|    critic_loss     | 7.87e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 130899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 7.4e+04  |
|    critic_loss     | 8.42e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 131299   |
---------------------------------
=== Iterazione IRL 94 ===
Loss reward (iter 94): -8355.279296875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 7.47e+04 |
|    critic_loss     | 9.79e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 131899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 7.51e+04 |
|    critic_loss     | 8.76e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 132299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 7.62e+04 |
|    critic_loss     | 9.34e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 132699   |
---------------------------------
=== Iterazione IRL 95 ===
Loss reward (iter 95): -8701.7587890625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 7.84e+04 |
|    critic_loss     | 1.17e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 133299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 7.84e+04 |
|    critic_loss     | 9.07e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 133699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 8.02e+04 |
|    critic_loss     | 9.73e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 134099   |
---------------------------------
=== Iterazione IRL 96 ===
Loss reward (iter 96): -8996.5849609375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 8.07e+04 |
|    critic_loss     | 1.06e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 134699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 8.1e+04  |
|    critic_loss     | 1.08e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 135099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 8.21e+04 |
|    critic_loss     | 1.07e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 135499   |
---------------------------------
=== Iterazione IRL 97 ===
Loss reward (iter 97): -9215.8671875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 8.35e+04 |
|    critic_loss     | 1.08e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 136099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 8.47e+04 |
|    critic_loss     | 1.13e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 136499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 8.54e+04 |
|    critic_loss     | 9.63e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 136899   |
---------------------------------
=== Iterazione IRL 98 ===
Loss reward (iter 98): -9617.052734375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 8.66e+04 |
|    critic_loss     | 9.16e+06 |
|    learning_rate   | 0.001    |
|    n_updates       | 137499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 8.67e+04 |
|    critic_loss     | 1.09e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 137899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 8.78e+04 |
|    critic_loss     | 1.15e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 138299   |
---------------------------------
=== Iterazione IRL 99 ===
Loss reward (iter 99): -9891.1806640625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 9.03e+04 |
|    critic_loss     | 1.18e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 138899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 9.07e+04 |
|    critic_loss     | 1.33e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 139299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 9.27e+04 |
|    critic_loss     | 1.24e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 139699   |
---------------------------------
=== Iterazione IRL 100 ===
Loss reward (iter 100): -10180.9326171875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 9.32e+04 |
|    critic_loss     | 1.3e+07  |
|    learning_rate   | 0.001    |
|    n_updates       | 140299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 231      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 9.49e+04 |
|    critic_loss     | 1.36e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 140699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 219      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 9.54e+04 |
|    critic_loss     | 1.3e+07  |
|    learning_rate   | 0.001    |
|    n_updates       | 141099   |
---------------------------------
=== Iterazione IRL 101 ===
Loss reward (iter 101): -10401.3681640625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 9.6e+04  |
|    critic_loss     | 1.19e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 141699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 9.77e+04 |
|    critic_loss     | 1.27e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 142099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 9.81e+04 |
|    critic_loss     | 1.38e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 142499   |
---------------------------------
=== Iterazione IRL 102 ===
Loss reward (iter 102): -10802.1474609375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 9.99e+04 |
|    critic_loss     | 1.51e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 143099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.02e+05 |
|    critic_loss     | 1.61e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 143499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.01e+05 |
|    critic_loss     | 1.53e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 143899   |
---------------------------------
=== Iterazione IRL 103 ===
Loss reward (iter 103): -11228.72265625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.04e+05 |
|    critic_loss     | 1.15e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 144499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.04e+05 |
|    critic_loss     | 1.56e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 144899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.06e+05 |
|    critic_loss     | 1.68e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 145299   |
---------------------------------
=== Iterazione IRL 104 ===
Loss reward (iter 104): -11420.7734375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.07e+05 |
|    critic_loss     | 1.83e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 145899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.09e+05 |
|    critic_loss     | 1.69e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 146299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.09e+05 |
|    critic_loss     | 1.63e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 146699   |
---------------------------------
=== Iterazione IRL 105 ===
Loss reward (iter 105): -11812.7880859375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.11e+05 |
|    critic_loss     | 1.64e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 147299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.12e+05 |
|    critic_loss     | 1.71e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 147699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.13e+05 |
|    critic_loss     | 1.72e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 148099   |
---------------------------------
=== Iterazione IRL 106 ===
Loss reward (iter 106): -12179.6796875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.15e+05 |
|    critic_loss     | 1.79e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 148699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 223      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.17e+05 |
|    critic_loss     | 1.85e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 149099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 214      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.17e+05 |
|    critic_loss     | 1.91e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 149499   |
---------------------------------
=== Iterazione IRL 107 ===
Loss reward (iter 107): -12504.76953125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.18e+05 |
|    critic_loss     | 1.83e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 150099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.19e+05 |
|    critic_loss     | 1.85e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 150499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.2e+05  |
|    critic_loss     | 2.16e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 150899   |
---------------------------------
=== Iterazione IRL 108 ===
Loss reward (iter 108): -12755.88671875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 256      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.22e+05 |
|    critic_loss     | 2.13e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 151499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.24e+05 |
|    critic_loss     | 2.32e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 151899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.24e+05 |
|    critic_loss     | 2.31e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 152299   |
---------------------------------
=== Iterazione IRL 109 ===
Loss reward (iter 109): -13267.912109375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 255      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.27e+05 |
|    critic_loss     | 2.27e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 152899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 224      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.27e+05 |
|    critic_loss     | 2.22e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 153299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 215      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.28e+05 |
|    critic_loss     | 2.13e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 153699   |
---------------------------------
=== Iterazione IRL 110 ===
Loss reward (iter 110): -13614.2509765625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.31e+05 |
|    critic_loss     | 2e+07    |
|    learning_rate   | 0.001    |
|    n_updates       | 154299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.32e+05 |
|    critic_loss     | 2.07e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 154699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.32e+05 |
|    critic_loss     | 2.52e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 155099   |
---------------------------------
=== Iterazione IRL 111 ===
Loss reward (iter 111): -14044.484375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 257      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.35e+05 |
|    critic_loss     | 2.3e+07  |
|    learning_rate   | 0.001    |
|    n_updates       | 155699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 225      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.36e+05 |
|    critic_loss     | 2.18e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 156099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 216      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.39e+05 |
|    critic_loss     | 2.3e+07  |
|    learning_rate   | 0.001    |
|    n_updates       | 156499   |
---------------------------------
=== Iterazione IRL 112 ===
Loss reward (iter 112): -14436.541015625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 268      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.4e+05  |
|    critic_loss     | 2.33e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 157099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 238      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.41e+05 |
|    critic_loss     | 2.25e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 157499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 229      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.42e+05 |
|    critic_loss     | 2.38e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 157899   |
---------------------------------
=== Iterazione IRL 113 ===
Loss reward (iter 113): -14723.5517578125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.46e+05 |
|    critic_loss     | 2.38e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 158499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.45e+05 |
|    critic_loss     | 2.67e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 158899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 229      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.47e+05 |
|    critic_loss     | 3.01e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 159299   |
---------------------------------
=== Iterazione IRL 114 ===
Loss reward (iter 114): -15139.4169921875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.49e+05 |
|    critic_loss     | 2.9e+07  |
|    learning_rate   | 0.001    |
|    n_updates       | 159899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.51e+05 |
|    critic_loss     | 2.98e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 160299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.52e+05 |
|    critic_loss     | 3.16e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 160699   |
---------------------------------
=== Iterazione IRL 115 ===
Loss reward (iter 115): -15837.890625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 271      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.54e+05 |
|    critic_loss     | 2.91e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 161299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.55e+05 |
|    critic_loss     | 3.18e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 161699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.57e+05 |
|    critic_loss     | 2.48e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 162099   |
---------------------------------
=== Iterazione IRL 116 ===
Loss reward (iter 116): -16043.08984375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 271      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.58e+05 |
|    critic_loss     | 3.78e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 162699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.6e+05  |
|    critic_loss     | 3.47e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 163099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.62e+05 |
|    critic_loss     | 3.69e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 163499   |
---------------------------------
=== Iterazione IRL 117 ===
Loss reward (iter 117): -16478.13671875
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 270      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.63e+05 |
|    critic_loss     | 4.23e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 164099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 237      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.67e+05 |
|    critic_loss     | 3.46e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 164499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 228      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.67e+05 |
|    critic_loss     | 2.62e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 164899   |
---------------------------------
=== Iterazione IRL 118 ===
Loss reward (iter 118): -17054.3515625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.69e+05 |
|    critic_loss     | 2.99e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 165499   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.71e+05 |
|    critic_loss     | 3.54e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 165899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 229      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.73e+05 |
|    critic_loss     | 3.44e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 166299   |
---------------------------------
=== Iterazione IRL 119 ===
Loss reward (iter 119): -17246.330078125
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 272      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.75e+05 |
|    critic_loss     | 4.05e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 166899   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 238      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.76e+05 |
|    critic_loss     | 3.42e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 167299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 229      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.78e+05 |
|    critic_loss     | 4.01e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 167699   |
---------------------------------
=== Iterazione IRL 120 ===
Loss reward (iter 120): -17633.859375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.8e+05  |
|    critic_loss     | 3.76e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 168299   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.82e+05 |
|    critic_loss     | 4.23e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 168699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.83e+05 |
|    critic_loss     | 3.37e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 169099   |
---------------------------------
=== Iterazione IRL 121 ===
Loss reward (iter 121): -18353.3359375
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.87e+05 |
|    critic_loss     | 4.35e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 169699   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 8        |
|    fps             | 239      |
|    time_elapsed    | 3        |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | 1.88e+05 |
|    critic_loss     | 4.01e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 170099   |
---------------------------------
---------------------------------
| time/              |          |
|    episodes        | 12       |
|    fps             | 230      |
|    time_elapsed    | 5        |
|    total_timesteps | 1200     |
| train/             |          |
|    actor_loss      | 1.89e+05 |
|    critic_loss     | 4.35e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 170499   |
---------------------------------
=== Iterazione IRL 122 ===
Loss reward (iter 122): -18748.259765625
>>> Aggiorno la policy con TD3
---------------------------------
| time/              |          |
|    episodes        | 4        |
|    fps             | 273      |
|    time_elapsed    | 1        |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | 1.91e+05 |
|    critic_loss     | 4.03e+07 |
|    learning_rate   | 0.001    |
|    n_updates       | 171099   |
---------------------------------

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "rot_error: 0.20803308486938477\n",
      "rot_error: 0.235848069190979\n",
      "rot_error: 0.14840292930603027\n",
      "rot_error: 0.009124159812927246\n",
      "rot_error: 0.14789187908172607\n",
      "rot_error: 0.3119209408760071\n",
      "rot_error: 0.45394521951675415\n",
      "rot_error: 0.5613267421722412\n",
      "rot_error: 0.6340967416763306\n",
      "rot_error: 0.6807144284248352\n",
      "rot_error: 0.698536217212677\n",
      "rot_error: 0.6558635830879211\n",
      "rot_error: 0.6084034442901611\n",
      "rot_error: 0.5495246648788452\n",
      "rot_error: 0.49893471598625183\n",
      "rot_error: 0.45132946968078613\n",
      "rot_error: 0.416618674993515\n",
      "rot_error: 0.37500014901161194\n",
      "rot_error: 0.3487994372844696\n",
      "rot_error: 0.3138151168823242\n",
      "rot_error: 0.28595784306526184\n",
      "rot_error: 0.2572562098503113\n",
      "rot_error: 0.24282468855381012\n",
      "rot_error: 0.2258298695087433\n",
      "rot_error: 0.21008269488811493\n",
      "rot_error: 0.19761142134666443\n",
      "rot_error: 0.17821955680847168\n",
      "rot_error: 0.16305793821811676\n",
      "rot_error: 0.1563364714384079\n",
      "rot_error: 0.15199686586856842\n",
      "rot_error: 0.14235267043113708\n",
      "rot_error: 0.13609856367111206\n",
      "rot_error: 0.12899233400821686\n",
      "rot_error: 0.12068331986665726\n",
      "rot_error: 0.11990902572870255\n",
      "rot_error: 0.10781216621398926\n",
      "rot_error: 0.10281356424093246\n",
      "rot_error: 0.09383318573236465\n",
      "rot_error: 0.08434391021728516\n",
      "rot_error: 0.07580356299877167\n",
      "rot_error: 0.0732402354478836\n",
      "rot_error: 0.07111033797264099\n",
      "rot_error: 0.07477974891662598\n",
      "rot_error: 0.0747213363647461\n",
      "rot_error: 0.07153822481632233\n",
      "rot_error: 0.06891757249832153\n",
      "rot_error: 0.07291757315397263\n",
      "rot_error: 0.06951902061700821\n",
      "rot_error: 0.07202641665935516\n",
      "rot_error: 0.07447860389947891\n",
      "rot_error: 0.07832477986812592\n",
      "rot_error: 0.07159321755170822\n",
      "rot_error: 0.06453057378530502\n",
      "rot_error: 0.05797155573964119\n",
      "rot_error: 0.06152172386646271\n",
      "rot_error: 0.059011299163103104\n",
      "rot_error: 0.05862141400575638\n",
      "rot_error: 0.05265331268310547\n",
      "rot_error: 0.05665331333875656\n",
      "rot_error: 0.05251746252179146\n",
      "rot_error: 0.05589696764945984\n",
      "rot_error: 0.05246712267398834\n",
      "rot_error: 0.051768749952316284\n",
      "rot_error: 0.05114823579788208\n",
      "rot_error: 0.04971196502447128\n",
      "rot_error: 0.04571196436882019\n",
      "rot_error: 0.04364705830812454\n",
      "rot_error: 0.03964705765247345\n",
      "rot_error: 0.03582722321152687\n",
      "rot_error: 0.032787054777145386\n",
      "rot_error: 0.034721799194812775\n",
      "rot_error: 0.03872179612517357\n",
      "rot_error: 0.0406026616692543\n",
      "rot_error: 0.044602662324905396\n",
      "rot_error: 0.04751686379313469\n",
      "rot_error: 0.050116077065467834\n",
      "rot_error: 0.05411607772111893\n",
      "rot_error: 0.05070212855935097\n",
      "rot_error: 0.048677314072847366\n",
      "rot_error: 0.05000879615545273\n",
      "rot_error: 0.046008795499801636\n",
      "rot_error: 0.04233342781662941\n",
      "rot_error: 0.0463334284722805\n",
      "rot_error: 0.04915691539645195\n",
      "rot_error: 0.0528569296002388\n",
      "rot_error: 0.05685693025588989\n",
      "rot_error: 0.05106665939092636\n",
      "rot_error: 0.05053830146789551\n",
      "rot_error: 0.046538300812244415\n",
      "rot_error: 0.044685330241918564\n",
      "rot_error: 0.04440085217356682\n",
      "rot_error: 0.04174826294183731\n",
      "rot_error: 0.03774826228618622\n",
      "rot_error: 0.035390790551900864\n",
      "rot_error: 0.03621763736009598\n",
      "rot_error: 0.03281572088599205\n",
      "rot_error: 0.029214011505246162\n",
      "rot_error: 0.026691703125834465\n",
      "rot_error: 0.023698898032307625\n",
      "rot_error: 0.023224815726280212\n",
      "Episode 0, Reward: -172.81, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "rot_error: 2.482846736907959\n",
      "rot_error: 2.2532718181610107\n",
      "rot_error: 2.0286495685577393\n",
      "rot_error: 1.8189942836761475\n",
      "rot_error: 1.6236997842788696\n",
      "rot_error: 1.443706750869751\n",
      "rot_error: 1.2796072959899902\n",
      "rot_error: 1.1336923837661743\n",
      "rot_error: 1.0096986293792725\n",
      "rot_error: 0.9016949534416199\n",
      "rot_error: 0.8049057722091675\n",
      "rot_error: 0.7244431972503662\n",
      "rot_error: 0.6624220609664917\n",
      "rot_error: 0.6048080325126648\n",
      "rot_error: 0.5540298223495483\n",
      "rot_error: 0.5038059949874878\n",
      "rot_error: 0.4627211391925812\n",
      "rot_error: 0.4240877628326416\n",
      "rot_error: 0.39216160774230957\n",
      "rot_error: 0.36570894718170166\n",
      "rot_error: 0.3447595238685608\n",
      "rot_error: 0.32125693559646606\n",
      "rot_error: 0.2942798137664795\n",
      "rot_error: 0.27178865671157837\n",
      "rot_error: 0.2564864456653595\n",
      "rot_error: 0.23748372495174408\n",
      "rot_error: 0.21795690059661865\n",
      "rot_error: 0.20342163741588593\n",
      "rot_error: 0.19235987961292267\n",
      "rot_error: 0.17964404821395874\n",
      "rot_error: 0.16904973983764648\n",
      "rot_error: 0.16126711666584015\n",
      "rot_error: 0.15912550687789917\n",
      "rot_error: 0.1588345170021057\n",
      "rot_error: 0.15857261419296265\n",
      "rot_error: 0.15303239226341248\n",
      "rot_error: 0.14624443650245667\n",
      "rot_error: 0.14724154770374298\n",
      "rot_error: 0.14813895523548126\n",
      "rot_error: 0.1375465989112854\n",
      "rot_error: 0.1394135057926178\n",
      "rot_error: 0.12969370186328888\n",
      "rot_error: 0.1288459748029709\n",
      "rot_error: 0.12538857758045197\n",
      "rot_error: 0.12487132847309113\n",
      "rot_error: 0.116605743765831\n",
      "rot_error: 0.10926643013954163\n",
      "rot_error: 0.10375961661338806\n",
      "rot_error: 0.10016561299562454\n",
      "rot_error: 0.10028426349163055\n",
      "rot_error: 0.09955117106437683\n",
      "rot_error: 0.10258765518665314\n",
      "rot_error: 0.10069786012172699\n",
      "rot_error: 0.10469785332679749\n",
      "rot_error: 0.10701100528240204\n",
      "rot_error: 0.11101099848747253\n",
      "rot_error: 0.10413146018981934\n",
      "rot_error: 0.0979398638010025\n",
      "rot_error: 0.1019398644566536\n",
      "rot_error: 0.10593986511230469\n",
      "rot_error: 0.10993985831737518\n",
      "rot_error: 0.10779637098312378\n",
      "rot_error: 0.1115061342716217\n",
      "rot_error: 0.1134948581457138\n",
      "rot_error: 0.10870522260665894\n",
      "rot_error: 0.10303610563278198\n",
      "rot_error: 0.10130508244037628\n",
      "rot_error: 0.10433182120323181\n",
      "rot_error: 0.10439732670783997\n",
      "rot_error: 0.10657649487257004\n",
      "rot_error: 0.10150498896837234\n",
      "rot_error: 0.10156089067459106\n",
      "rot_error: 0.10412019491195679\n",
      "rot_error: 0.09792973101139069\n",
      "rot_error: 0.09449884295463562\n",
      "rot_error: 0.09220094978809357\n",
      "rot_error: 0.09432562440633774\n",
      "rot_error: 0.09114858508110046\n",
      "rot_error: 0.09263864904642105\n",
      "rot_error: 0.09202349185943604\n",
      "rot_error: 0.09337949007749557\n",
      "rot_error: 0.09165798127651215\n",
      "rot_error: 0.0928228497505188\n",
      "rot_error: 0.09152689576148987\n",
      "rot_error: 0.08752689510583878\n",
      "rot_error: 0.08612920343875885\n",
      "rot_error: 0.0874423012137413\n",
      "rot_error: 0.08344230055809021\n",
      "rot_error: 0.07944229990243912\n",
      "rot_error: 0.07779009640216827\n",
      "rot_error: 0.07852417230606079\n",
      "rot_error: 0.07513588666915894\n",
      "rot_error: 0.07542949914932251\n",
      "rot_error: 0.07677030563354492\n",
      "rot_error: 0.07569946348667145\n",
      "rot_error: 0.07721464335918427\n",
      "rot_error: 0.08069700002670288\n",
      "rot_error: 0.08469700813293457\n",
      "rot_error: 0.08069700002670288\n",
      "rot_error: 0.08048199117183685\n",
      "rot_error: 5.0633392333984375\n",
      "rot_error: 4.620850563049316\n",
      "rot_error: 4.100987911224365\n",
      "rot_error: 3.565739154815674\n",
      "rot_error: 3.05045223236084\n",
      "rot_error: 2.5711615085601807\n",
      "rot_error: 2.138753652572632\n",
      "rot_error: 1.7777328491210938\n",
      "rot_error: 1.4727426767349243\n",
      "rot_error: 1.2248940467834473\n",
      "rot_error: 1.0277490615844727\n",
      "rot_error: 0.8997023105621338\n",
      "rot_error: 0.8015244007110596\n",
      "rot_error: 0.7241531014442444\n",
      "rot_error: 0.6592089533805847\n",
      "rot_error: 0.6010600924491882\n",
      "rot_error: 0.5472275018692017\n",
      "rot_error: 0.4916834235191345\n",
      "rot_error: 0.44934502243995667\n",
      "rot_error: 0.4137214422225952\n",
      "rot_error: 0.3719095289707184\n",
      "rot_error: 0.3453159034252167\n",
      "rot_error: 0.32138174772262573\n",
      "rot_error: 0.2962639629840851\n",
      "rot_error: 0.27357980608940125\n",
      "rot_error: 0.24760451912879944\n",
      "rot_error: 0.22587694227695465\n",
      "rot_error: 0.20923112332820892\n",
      "rot_error: 0.1972062587738037\n",
      "rot_error: 0.17892608046531677\n",
      "rot_error: 0.17163094878196716\n",
      "rot_error: 0.15990789234638214\n",
      "rot_error: 0.14902128279209137\n",
      "rot_error: 0.13815374672412872\n",
      "rot_error: 0.12747687101364136\n",
      "rot_error: 0.1153893694281578\n",
      "rot_error: 0.10863615572452545\n",
      "rot_error: 0.10709304362535477\n",
      "rot_error: 0.09895116090774536\n",
      "rot_error: 0.09125757962465286\n",
      "rot_error: 0.08132929354906082\n",
      "rot_error: 0.08379384130239487\n",
      "rot_error: 0.07735971361398697\n",
      "rot_error: 0.07881450653076172\n",
      "rot_error: 0.08107899129390717\n",
      "rot_error: 0.07216856628656387\n",
      "rot_error: 0.06703570485115051\n",
      "rot_error: 0.06123754754662514\n",
      "rot_error: 0.054311271756887436\n",
      "rot_error: 0.05711555853486061\n",
      "rot_error: 0.05961529538035393\n",
      "rot_error: 0.061745937913656235\n",
      "rot_error: 0.05692335590720177\n",
      "rot_error: 0.05753081664443016\n",
      "rot_error: 0.055657293647527695\n",
      "rot_error: 0.051507316529750824\n",
      "rot_error: 0.04650105908513069\n",
      "rot_error: 0.050501056015491486\n",
      "rot_error: 0.04879598319530487\n",
      "rot_error: 0.04479598253965378\n",
      "rot_error: 0.0446782112121582\n",
      "rot_error: 0.04673454910516739\n",
      "rot_error: 0.048465024679899216\n",
      "rot_error: 0.05037228763103485\n",
      "rot_error: 0.05111369490623474\n",
      "rot_error: 0.04977438226342201\n",
      "rot_error: 0.04817007854580879\n",
      "rot_error: 0.0441700778901577\n",
      "rot_error: 0.04017007723450661\n",
      "rot_error: 0.036170076578855515\n",
      "rot_error: 0.03784371167421341\n",
      "rot_error: 0.04150841012597084\n",
      "rot_error: 0.04164258763194084\n",
      "rot_error: 0.04562564566731453\n",
      "rot_error: 0.04581863805651665\n",
      "rot_error: 0.04428683593869209\n",
      "rot_error: 0.043127622455358505\n",
      "rot_error: 0.04524413123726845\n",
      "rot_error: 0.047785788774490356\n",
      "rot_error: 0.05006124824285507\n",
      "rot_error: 0.05226265266537666\n",
      "rot_error: 0.056262653321027756\n",
      "rot_error: 0.05870577320456505\n",
      "rot_error: 0.05582278594374657\n",
      "rot_error: 0.05613867565989494\n",
      "rot_error: 0.05905333533883095\n",
      "rot_error: 0.06098483130335808\n",
      "rot_error: 0.054083824157714844\n",
      "rot_error: 0.05603386461734772\n",
      "rot_error: 0.04962795600295067\n",
      "rot_error: 0.046209003776311874\n",
      "rot_error: 0.04417865723371506\n",
      "rot_error: 0.040178656578063965\n",
      "rot_error: 0.03958836942911148\n",
      "rot_error: 0.03811164200305939\n",
      "rot_error: 0.034111641347408295\n",
      "rot_error: 0.03811164200305939\n",
      "rot_error: 0.034111641347408295\n",
      "rot_error: 0.03311152756214142\n",
      "rot_error: 0.03199300542473793\n",
      "rot_error: 3.782179832458496\n",
      "rot_error: 3.4739534854888916\n",
      "rot_error: 3.069766044616699\n",
      "rot_error: 2.6200075149536133\n",
      "rot_error: 2.167139768600464\n",
      "rot_error: 1.7467925548553467\n",
      "rot_error: 1.3658111095428467\n",
      "rot_error: 1.0487704277038574\n",
      "rot_error: 0.7864347696304321\n",
      "rot_error: 0.5883867144584656\n",
      "rot_error: 0.43352967500686646\n",
      "rot_error: 0.3712604343891144\n",
      "rot_error: 0.3326530158519745\n",
      "rot_error: 0.30637216567993164\n",
      "rot_error: 0.2783418297767639\n",
      "rot_error: 0.2598642408847809\n",
      "rot_error: 0.23844288289546967\n",
      "rot_error: 0.21477293968200684\n",
      "rot_error: 0.19462531805038452\n",
      "rot_error: 0.1833956390619278\n",
      "rot_error: 0.1634635627269745\n",
      "rot_error: 0.14531275629997253\n",
      "rot_error: 0.13343410193920135\n",
      "rot_error: 0.11828641593456268\n",
      "rot_error: 0.1046704649925232\n",
      "rot_error: 0.10175950825214386\n",
      "rot_error: 0.10117929428815842\n",
      "rot_error: 0.09129229187965393\n",
      "rot_error: 0.09116684645414352\n",
      "rot_error: 0.08291696012020111\n",
      "rot_error: 0.0842210054397583\n",
      "rot_error: 0.08083686977624893\n",
      "rot_error: 0.0748433768749237\n",
      "rot_error: 0.0680079236626625\n",
      "rot_error: 0.07080287486314774\n",
      "rot_error: 0.06831859052181244\n",
      "rot_error: 0.06393589079380035\n",
      "rot_error: 0.0651370957493782\n",
      "rot_error: 0.0568191260099411\n",
      "rot_error: 0.06073296070098877\n",
      "rot_error: 0.06425540149211884\n",
      "rot_error: 0.06677009165287018\n",
      "rot_error: 0.0696888193488121\n",
      "rot_error: 0.0688844844698906\n",
      "rot_error: 0.0627785176038742\n",
      "rot_error: 0.06609640270471573\n",
      "rot_error: 0.06778969615697861\n",
      "rot_error: 0.05920647084712982\n",
      "rot_error: 0.05148155987262726\n",
      "rot_error: 0.05221754312515259\n",
      "rot_error: 0.051345787942409515\n",
      "rot_error: 0.047315552830696106\n",
      "rot_error: 0.0513155460357666\n",
      "rot_error: 0.04811021685600281\n",
      "rot_error: 0.04938492923974991\n",
      "rot_error: 0.04971831291913986\n",
      "rot_error: 0.04825291782617569\n",
      "rot_error: 0.047636836767196655\n",
      "rot_error: 0.047234341502189636\n",
      "rot_error: 0.04839584231376648\n",
      "rot_error: 0.05239584296941757\n",
      "rot_error: 0.04535200446844101\n",
      "rot_error: 0.041182100772857666\n",
      "rot_error: 0.042062610387802124\n",
      "rot_error: 0.04262568801641464\n",
      "rot_error: 0.04194915294647217\n",
      "rot_error: 0.04594915360212326\n",
      "rot_error: 0.03954997658729553\n",
      "rot_error: 0.04077119380235672\n",
      "rot_error: 0.042096614837646484\n",
      "rot_error: 0.04609661549329758\n",
      "rot_error: 0.04995828866958618\n",
      "rot_error: 0.052275098860263824\n",
      "rot_error: 0.05627509951591492\n",
      "rot_error: 0.053577013313770294\n",
      "rot_error: 0.0464150533080101\n",
      "rot_error: 0.040047787129879\n",
      "rot_error: 0.034238748252391815\n",
      "rot_error: 0.03150425851345062\n",
      "rot_error: 0.030220238491892815\n",
      "rot_error: 0.026220237836241722\n",
      "rot_error: 0.030220238491892815\n",
      "rot_error: 0.032607585191726685\n",
      "rot_error: 0.03374318778514862\n",
      "rot_error: 0.030746465548872948\n",
      "rot_error: 0.030366988852620125\n",
      "rot_error: 0.031098129227757454\n",
      "rot_error: 0.02709812857210636\n",
      "rot_error: 0.023189010098576546\n",
      "rot_error: 0.01933644525706768\n",
      "rot_error: 0.016948888078331947\n",
      "rot_error: 0.018720300868153572\n",
      "rot_error: 0.019627084955573082\n",
      "rot_error: 0.017925849184393883\n",
      "rot_error: 0.018133817240595818\n",
      "rot_error: 0.015500465407967567\n",
      "rot_error: 0.011500466614961624\n",
      "rot_error: 0.01508607342839241\n",
      "rot_error: 0.012410545721650124\n",
      "rot_error: 0.016410546377301216\n",
      "rot_error: 0.9379466772079468\n",
      "rot_error: 0.8989216089248657\n",
      "rot_error: 0.7358617782592773\n",
      "rot_error: 0.5102006196975708\n",
      "rot_error: 0.2661482095718384\n",
      "rot_error: 0.029590189456939697\n",
      "rot_error: 0.17079538106918335\n",
      "rot_error: 0.3377190828323364\n",
      "rot_error: 0.4616536498069763\n",
      "rot_error: 0.5442727208137512\n",
      "rot_error: 0.588463306427002\n",
      "rot_error: 0.5624180436134338\n",
      "rot_error: 0.5198725461959839\n",
      "rot_error: 0.48206332325935364\n",
      "rot_error: 0.435494989156723\n",
      "rot_error: 0.4005679786205292\n",
      "rot_error: 0.3614785671234131\n",
      "rot_error: 0.3337104022502899\n",
      "rot_error: 0.3029215931892395\n",
      "rot_error: 0.28493112325668335\n",
      "rot_error: 0.26873835921287537\n",
      "rot_error: 0.24276448786258698\n",
      "rot_error: 0.22462621331214905\n",
      "rot_error: 0.2104174643754959\n",
      "rot_error: 0.19977766275405884\n",
      "rot_error: 0.19070032238960266\n",
      "rot_error: 0.17807374894618988\n",
      "rot_error: 0.16417156159877777\n",
      "rot_error: 0.14865419268608093\n",
      "rot_error: 0.14608857035636902\n",
      "rot_error: 0.14154964685440063\n",
      "rot_error: 0.13098736107349396\n",
      "rot_error: 0.12412650883197784\n",
      "rot_error: 0.11913751810789108\n",
      "rot_error: 0.10812356323003769\n",
      "rot_error: 0.09821100533008575\n",
      "rot_error: 0.09848209470510483\n",
      "rot_error: 0.09426954388618469\n",
      "rot_error: 0.08896295726299286\n",
      "rot_error: 0.09236645698547363\n",
      "rot_error: 0.09542960673570633\n",
      "rot_error: 0.0981864482164383\n",
      "rot_error: 0.09824994206428528\n",
      "rot_error: 0.09280137717723846\n",
      "rot_error: 0.09021217375993729\n",
      "rot_error: 0.09332720190286636\n",
      "rot_error: 0.09075336158275604\n",
      "rot_error: 0.09331271052360535\n",
      "rot_error: 0.09628123790025711\n",
      "rot_error: 0.09444661438465118\n",
      "rot_error: 0.09504814445972443\n",
      "rot_error: 0.09491997212171555\n",
      "rot_error: 0.08781111985445023\n",
      "rot_error: 0.07992980629205704\n",
      "rot_error: 0.07592445611953735\n",
      "rot_error: 0.07415885478258133\n",
      "rot_error: 0.07815885543823242\n",
      "rot_error: 0.08068034052848816\n",
      "rot_error: 0.07351210713386536\n",
      "rot_error: 0.07653306424617767\n",
      "rot_error: 0.07731598615646362\n",
      "rot_error: 0.0730227530002594\n",
      "rot_error: 0.07559097558259964\n",
      "rot_error: 0.07310497015714645\n",
      "rot_error: 0.0693342536687851\n",
      "rot_error: 0.07268324494361877\n",
      "rot_error: 0.0663147121667862\n",
      "rot_error: 0.06742008030414581\n",
      "rot_error: 0.06238652765750885\n",
      "rot_error: 0.06125977635383606\n",
      "rot_error: 0.05930149555206299\n",
      "rot_error: 0.055301494896411896\n",
      "rot_error: 0.053707219660282135\n",
      "rot_error: 0.05136831849813461\n",
      "rot_error: 0.05013679713010788\n",
      "rot_error: 0.04613679647445679\n",
      "rot_error: 0.04313194006681442\n",
      "rot_error: 0.04044726490974426\n",
      "rot_error: 0.041282445192337036\n",
      "rot_error: 0.038935352116823196\n",
      "rot_error: 0.04293534904718399\n",
      "rot_error: 0.045369796454906464\n",
      "rot_error: 0.048502787947654724\n",
      "rot_error: 0.04683005064725876\n",
      "rot_error: 0.04394901543855667\n",
      "rot_error: 0.045544855296611786\n",
      "rot_error: 0.04954485595226288\n",
      "rot_error: 0.045544855296611786\n",
      "rot_error: 0.04779713600873947\n",
      "rot_error: 0.043797142803668976\n",
      "rot_error: 0.03979714214801788\n",
      "rot_error: 0.04199666529893875\n",
      "rot_error: 0.04267587512731552\n",
      "rot_error: 0.03886431083083153\n",
      "rot_error: 0.04286430776119232\n",
      "rot_error: 0.046864308416843414\n",
      "rot_error: 0.04286430776119232\n",
      "rot_error: 0.03886431083083153\n",
      "rot_error: 0.039768047630786896\n",
      "rot_error: 0.0357680469751358\n",
      "rot_error: 2.0365195274353027\n",
      "rot_error: 1.8982644081115723\n",
      "rot_error: 1.6220619678497314\n",
      "rot_error: 1.290433645248413\n",
      "rot_error: 0.9335346817970276\n",
      "rot_error: 0.6017673015594482\n",
      "rot_error: 0.3086610436439514\n",
      "rot_error: 0.06346172094345093\n",
      "rot_error: 0.11640962958335876\n",
      "rot_error: 0.25102144479751587\n",
      "rot_error: 0.34285804629325867\n",
      "rot_error: 0.34924325346946716\n",
      "rot_error: 0.33725571632385254\n",
      "rot_error: 0.3198578953742981\n",
      "rot_error: 0.29384660720825195\n",
      "rot_error: 0.26678431034088135\n",
      "rot_error: 0.24680359661579132\n",
      "rot_error: 0.22955507040023804\n",
      "rot_error: 0.21336300671100616\n",
      "rot_error: 0.19929862022399902\n",
      "rot_error: 0.18464812636375427\n",
      "rot_error: 0.17964321374893188\n",
      "rot_error: 0.16932128369808197\n",
      "rot_error: 0.15444886684417725\n",
      "rot_error: 0.14950861036777496\n",
      "rot_error: 0.13661743700504303\n",
      "rot_error: 0.13237574696540833\n",
      "rot_error: 0.12734243273735046\n",
      "rot_error: 0.12067227065563202\n",
      "rot_error: 0.1106647253036499\n",
      "rot_error: 0.10213643312454224\n",
      "rot_error: 0.09398248046636581\n",
      "rot_error: 0.09196119755506516\n",
      "rot_error: 0.09533737599849701\n",
      "rot_error: 0.09546857327222824\n",
      "rot_error: 0.09127672016620636\n",
      "rot_error: 0.08977388590574265\n",
      "rot_error: 0.08598847687244415\n",
      "rot_error: 0.08621616661548615\n",
      "rot_error: 0.07965423166751862\n",
      "rot_error: 0.07834716886281967\n",
      "rot_error: 0.0795276090502739\n",
      "rot_error: 0.08352760970592499\n",
      "rot_error: 0.08360855281352997\n",
      "rot_error: 0.07730738073587418\n",
      "rot_error: 0.07932259887456894\n",
      "rot_error: 0.08027765899896622\n",
      "rot_error: 0.08395842462778091\n",
      "rot_error: 0.07762226462364197\n",
      "rot_error: 0.07934588938951492\n",
      "rot_error: 0.08295206725597382\n",
      "rot_error: 0.07671654224395752\n",
      "rot_error: 0.07558917999267578\n",
      "rot_error: 0.07748547941446304\n",
      "rot_error: 0.0769837498664856\n",
      "rot_error: 0.07968904823064804\n",
      "rot_error: 0.07749086618423462\n",
      "rot_error: 0.07349086552858353\n",
      "rot_error: 0.07081126421689987\n",
      "rot_error: 0.07470044493675232\n",
      "rot_error: 0.07870044559240341\n",
      "rot_error: 0.07906422764062881\n",
      "rot_error: 0.07488971203565598\n",
      "rot_error: 0.07592765241861343\n",
      "rot_error: 0.07966099679470062\n",
      "rot_error: 0.07486627250909805\n",
      "rot_error: 0.07576028257608414\n",
      "rot_error: 0.07697200775146484\n",
      "rot_error: 0.08097200840711594\n",
      "rot_error: 0.07493449002504349\n",
      "rot_error: 0.07465783506631851\n",
      "rot_error: 0.07370994985103607\n",
      "rot_error: 0.07295674085617065\n",
      "rot_error: 0.07025620341300964\n",
      "rot_error: 0.06822061538696289\n",
      "rot_error: 0.06442373991012573\n",
      "rot_error: 0.06042373925447464\n",
      "rot_error: 0.06442373991012573\n",
      "rot_error: 0.06042373925447464\n",
      "rot_error: 0.05822783708572388\n",
      "rot_error: 0.060714416205883026\n",
      "rot_error: 0.06471441686153412\n",
      "rot_error: 0.0664297565817833\n",
      "rot_error: 0.06676442176103592\n",
      "rot_error: 0.0664389580488205\n",
      "rot_error: 0.0694417729973793\n",
      "rot_error: 0.0734417736530304\n",
      "rot_error: 0.07076747715473175\n",
      "rot_error: 0.07204294949769974\n",
      "rot_error: 0.07196105271577835\n",
      "rot_error: 0.07478920370340347\n",
      "rot_error: 0.07878920435905457\n",
      "rot_error: 0.08278920501470566\n",
      "rot_error: 0.08143996447324753\n",
      "rot_error: 0.08251389861106873\n",
      "rot_error: 0.08538490533828735\n",
      "rot_error: 0.08535639196634293\n",
      "rot_error: 0.08795171231031418\n",
      "rot_error: 0.09195171296596527\n",
      "rot_error: 0.0904134213924408\n",
      "rot_error: 3.654122829437256\n",
      "rot_error: 3.3506429195404053\n",
      "rot_error: 2.9631786346435547\n",
      "rot_error: 2.533346652984619\n",
      "rot_error: 2.108428955078125\n",
      "rot_error: 1.7223788499832153\n",
      "rot_error: 1.381580114364624\n",
      "rot_error: 1.0887691974639893\n",
      "rot_error: 0.852910578250885\n",
      "rot_error: 0.6575263738632202\n",
      "rot_error: 0.5083653926849365\n",
      "rot_error: 0.43613046407699585\n",
      "rot_error: 0.395438551902771\n",
      "rot_error: 0.3572056293487549\n",
      "rot_error: 0.33105966448783875\n",
      "rot_error: 0.2991654574871063\n",
      "rot_error: 0.2693735659122467\n",
      "rot_error: 0.2471221685409546\n",
      "rot_error: 0.22471292316913605\n",
      "rot_error: 0.20492586493492126\n",
      "rot_error: 0.19240666925907135\n",
      "rot_error: 0.17605797946453094\n",
      "rot_error: 0.16263118386268616\n",
      "rot_error: 0.14544343948364258\n",
      "rot_error: 0.14137445390224457\n",
      "rot_error: 0.13487066328525543\n",
      "rot_error: 0.12169787287712097\n",
      "rot_error: 0.11163561046123505\n",
      "rot_error: 0.09954743087291718\n",
      "rot_error: 0.08915966749191284\n",
      "rot_error: 0.09071908891201019\n",
      "rot_error: 0.08925779908895493\n",
      "rot_error: 0.09080740064382553\n",
      "rot_error: 0.08917243033647537\n",
      "rot_error: 0.0867941603064537\n",
      "rot_error: 0.0809546634554863\n",
      "rot_error: 0.07979047298431396\n",
      "rot_error: 0.07630881667137146\n",
      "rot_error: 0.06832274049520493\n",
      "rot_error: 0.07196585088968277\n",
      "rot_error: 0.07524465024471283\n",
      "rot_error: 0.07413189113140106\n",
      "rot_error: 0.07466430217027664\n",
      "rot_error: 0.07112835347652435\n",
      "rot_error: 0.07217669486999512\n",
      "rot_error: 0.07085490971803665\n",
      "rot_error: 0.07424480468034744\n",
      "rot_error: 0.07392235100269318\n",
      "rot_error: 0.06776019185781479\n",
      "rot_error: 0.06868840754032135\n",
      "rot_error: 0.06296578794717789\n",
      "rot_error: 0.06574351340532303\n",
      "rot_error: 0.0659552812576294\n",
      "rot_error: 0.05914044752717018\n",
      "rot_error: 0.05418109521269798\n",
      "rot_error: 0.05180349200963974\n",
      "rot_error: 0.05141972750425339\n",
      "rot_error: 0.055167056620121\n",
      "rot_error: 0.05007147043943405\n",
      "rot_error: 0.04875332489609718\n",
      "rot_error: 0.05129637196660042\n",
      "rot_error: 0.0524122454226017\n",
      "rot_error: 0.04624640569090843\n",
      "rot_error: 0.050246406346559525\n",
      "rot_error: 0.053473856300115585\n",
      "rot_error: 0.05549890175461769\n",
      "rot_error: 0.05696798488497734\n",
      "rot_error: 0.05034656822681427\n",
      "rot_error: 0.047125089913606644\n",
      "rot_error: 0.051125090569257736\n",
      "rot_error: 0.048940159380435944\n",
      "rot_error: 0.04391082003712654\n",
      "rot_error: 0.03991081938147545\n",
      "rot_error: 0.04340646043419838\n",
      "rot_error: 0.046808499842882156\n",
      "rot_error: 0.046407394111156464\n",
      "rot_error: 0.04240739345550537\n",
      "rot_error: 0.0461096316576004\n",
      "rot_error: 0.04647339880466461\n",
      "rot_error: 0.04522387310862541\n",
      "rot_error: 0.04467836394906044\n",
      "rot_error: 0.047085102647542953\n",
      "rot_error: 0.044900987297296524\n",
      "rot_error: 0.04432230815291405\n",
      "rot_error: 0.045635174959897995\n",
      "rot_error: 0.0416351743042469\n",
      "rot_error: 0.044318243861198425\n",
      "rot_error: 0.04758881404995918\n",
      "rot_error: 0.04413281008601189\n",
      "rot_error: 0.04813281074166298\n",
      "rot_error: 0.046266552060842514\n",
      "rot_error: 0.04562805965542793\n",
      "rot_error: 0.04859134182333946\n",
      "rot_error: 0.04287942498922348\n",
      "rot_error: 0.04687942564487457\n",
      "rot_error: 0.04584197700023651\n",
      "rot_error: 0.04184197634458542\n",
      "rot_error: 0.04471511393785477\n",
      "rot_error: 0.047407571226358414\n",
      "rot_error: 0.04513157159090042\n",
      "rot_error: 0.05755490064620972\n",
      "rot_error: 0.02782607078552246\n",
      "rot_error: 0.046340763568878174\n",
      "rot_error: 0.08101660013198853\n",
      "rot_error: 0.1363014280796051\n",
      "rot_error: 0.1861792802810669\n",
      "rot_error: 0.2329844832420349\n",
      "rot_error: 0.2578675448894501\n",
      "rot_error: 0.282609760761261\n",
      "rot_error: 0.2888883054256439\n",
      "rot_error: 0.29039883613586426\n",
      "rot_error: 0.26570212841033936\n",
      "rot_error: 0.23786211013793945\n",
      "rot_error: 0.2188316136598587\n",
      "rot_error: 0.2048659473657608\n",
      "rot_error: 0.1879504770040512\n",
      "rot_error: 0.17687025666236877\n",
      "rot_error: 0.16688381135463715\n",
      "rot_error: 0.14977023005485535\n",
      "rot_error: 0.13401535153388977\n",
      "rot_error: 0.11851957440376282\n",
      "rot_error: 0.10597823560237885\n",
      "rot_error: 0.09915044158697128\n",
      "rot_error: 0.08779650926589966\n",
      "rot_error: 0.08367897570133209\n",
      "rot_error: 0.07768047600984573\n",
      "rot_error: 0.07394102215766907\n",
      "rot_error: 0.06957058608531952\n",
      "rot_error: 0.058907922357320786\n",
      "rot_error: 0.04931152984499931\n",
      "rot_error: 0.052074771374464035\n",
      "rot_error: 0.04471299424767494\n",
      "rot_error: 0.044547539204359055\n",
      "rot_error: 0.03877012059092522\n",
      "rot_error: 0.0311875082552433\n",
      "rot_error: 0.0351875014603138\n",
      "rot_error: 0.03438930585980415\n",
      "rot_error: 0.03301523998379707\n",
      "rot_error: 0.02667546644806862\n",
      "rot_error: 0.024875085800886154\n",
      "rot_error: 0.018681973218917847\n",
      "rot_error: 0.014681972563266754\n",
      "rot_error: 0.01669245958328247\n",
      "rot_error: 0.018635056912899017\n",
      "rot_error: 0.02263505756855011\n",
      "rot_error: 0.026635058224201202\n",
      "rot_error: 0.030635055154561996\n",
      "rot_error: 0.03454488143324852\n",
      "rot_error: 0.02863796427845955\n",
      "rot_error: 0.022068563848733902\n",
      "rot_error: 0.0213724747300148\n",
      "rot_error: 0.018264129757881165\n",
      "rot_error: 0.015673406422138214\n",
      "rot_error: 0.019650258123874664\n",
      "rot_error: 0.015650257468223572\n",
      "rot_error: 0.01638011634349823\n",
      "rot_error: 0.017658058553934097\n",
      "rot_error: 0.01567535102367401\n",
      "rot_error: 0.012333579361438751\n",
      "rot_error: 0.016333580017089844\n",
      "rot_error: 0.014510400593280792\n",
      "rot_error: 0.011846672743558884\n",
      "rot_error: 0.009076450020074844\n",
      "rot_error: 0.009362451732158661\n",
      "rot_error: 0.005816061049699783\n",
      "rot_error: 0.005618546158075333\n",
      "rot_error: 0.0028351731598377228\n",
      "rot_error: 0.004931826144456863\n",
      "rot_error: 0.006840396672487259\n",
      "rot_error: 0.008402515202760696\n",
      "rot_error: 0.005679227411746979\n",
      "rot_error: 0.004638548940420151\n",
      "rot_error: 0.008638549596071243\n",
      "rot_error: 0.012638550251722336\n",
      "rot_error: 0.01514539122581482\n",
      "rot_error: 0.019145388156175613\n",
      "rot_error: 0.019766181707382202\n",
      "rot_error: 0.017766457051038742\n",
      "rot_error: 0.019199110567569733\n",
      "rot_error: 0.018161412328481674\n",
      "rot_error: 0.016790911555290222\n",
      "rot_error: 0.01981193944811821\n",
      "rot_error: 0.016264475882053375\n",
      "rot_error: 0.019966892898082733\n",
      "rot_error: 0.020298819988965988\n",
      "rot_error: 0.024297963827848434\n",
      "rot_error: 0.027172602713108063\n",
      "rot_error: 0.027990851551294327\n",
      "rot_error: 0.03199085220694542\n",
      "rot_error: 0.03599085286259651\n",
      "rot_error: 0.03999084606766701\n",
      "rot_error: 0.03644362464547157\n",
      "rot_error: 0.032574091106653214\n",
      "rot_error: 0.02561107650399208\n",
      "rot_error: 0.029611077159643173\n",
      "rot_error: 0.028995629400014877\n",
      "rot_error: 0.02488325536251068\n",
      "rot_error: 0.02537769451737404\n",
      "rot_error: 0.025579050183296204\n",
      "rot_error: 0.029579047113656998\n",
      "rot_error: 2.405473470687866\n",
      "rot_error: 2.210078477859497\n",
      "rot_error: 1.9564180374145508\n",
      "rot_error: 1.6835825443267822\n",
      "rot_error: 1.4087309837341309\n",
      "rot_error: 1.1543281078338623\n",
      "rot_error: 0.9302440881729126\n",
      "rot_error: 0.7360296249389648\n",
      "rot_error: 0.5833043456077576\n",
      "rot_error: 0.45267611742019653\n",
      "rot_error: 0.35742783546447754\n",
      "rot_error: 0.31562110781669617\n",
      "rot_error: 0.2914818227291107\n",
      "rot_error: 0.2724618911743164\n",
      "rot_error: 0.2516823709011078\n",
      "rot_error: 0.22924748063087463\n",
      "rot_error: 0.20738209784030914\n",
      "rot_error: 0.19183139503002167\n",
      "rot_error: 0.18267011642456055\n",
      "rot_error: 0.16771572828292847\n",
      "rot_error: 0.16344577074050903\n",
      "rot_error: 0.1482030600309372\n",
      "rot_error: 0.14328515529632568\n",
      "rot_error: 0.1376049816608429\n",
      "rot_error: 0.12932829558849335\n",
      "rot_error: 0.12889742851257324\n",
      "rot_error: 0.1280261129140854\n",
      "rot_error: 0.12545478343963623\n",
      "rot_error: 0.1223846971988678\n",
      "rot_error: 0.1117212325334549\n",
      "rot_error: 0.11287423968315125\n",
      "rot_error: 0.1086864322423935\n",
      "rot_error: 0.10337439179420471\n",
      "rot_error: 0.10228179395198822\n",
      "rot_error: 0.10455559194087982\n",
      "rot_error: 0.0952020138502121\n",
      "rot_error: 0.08754287660121918\n",
      "rot_error: 0.08559605479240417\n",
      "rot_error: 0.07813842594623566\n",
      "rot_error: 0.07856222987174988\n",
      "rot_error: 0.07184390723705292\n",
      "rot_error: 0.07011672109365463\n",
      "rot_error: 0.06819310784339905\n",
      "rot_error: 0.06256154179573059\n",
      "rot_error: 0.06366962194442749\n",
      "rot_error: 0.06520991027355194\n",
      "rot_error: 0.06920991092920303\n",
      "rot_error: 0.06792587041854858\n",
      "rot_error: 0.07192587107419968\n",
      "rot_error: 0.07185114920139313\n",
      "rot_error: 0.06801194697618484\n",
      "rot_error: 0.0660439282655716\n",
      "rot_error: 0.06350461393594742\n",
      "rot_error: 0.06276041269302368\n",
      "rot_error: 0.06632307916879654\n",
      "rot_error: 0.06232307851314545\n",
      "rot_error: 0.06469811499118805\n",
      "rot_error: 0.06501521170139313\n",
      "rot_error: 0.0678112581372261\n",
      "rot_error: 0.0718112587928772\n",
      "rot_error: 0.07581125199794769\n",
      "rot_error: 0.07229804992675781\n",
      "rot_error: 0.07297664880752563\n",
      "rot_error: 0.07697664201259613\n",
      "rot_error: 0.07038095593452454\n",
      "rot_error: 0.06889443099498749\n",
      "rot_error: 0.06311005353927612\n",
      "rot_error: 0.05911005660891533\n",
      "rot_error: 0.0554860420525074\n",
      "rot_error: 0.05948604270815849\n",
      "rot_error: 0.0554860420525074\n",
      "rot_error: 0.05767976492643356\n",
      "rot_error: 0.06004864349961281\n",
      "rot_error: 0.056048642843961716\n",
      "rot_error: 0.05823850631713867\n",
      "rot_error: 0.06054685264825821\n",
      "rot_error: 0.05654685199260712\n",
      "rot_error: 0.052546851336956024\n",
      "rot_error: 0.0552419014275074\n",
      "rot_error: 0.058146920055150986\n",
      "rot_error: 0.06000622361898422\n",
      "rot_error: 0.06243577226996422\n",
      "rot_error: 0.06226978823542595\n",
      "rot_error: 0.06626978516578674\n",
      "rot_error: 0.06873734295368195\n",
      "rot_error: 0.07273735105991364\n",
      "rot_error: 0.07366689294576645\n",
      "rot_error: 0.07322457432746887\n",
      "rot_error: 0.06804685294628143\n",
      "rot_error: 0.06243376433849335\n",
      "rot_error: 0.06491531431674957\n",
      "rot_error: 0.0653981864452362\n",
      "rot_error: 0.06139818951487541\n",
      "rot_error: 0.061404015868902206\n",
      "rot_error: 0.058438435196876526\n",
      "rot_error: 0.06243843585252762\n",
      "rot_error: 0.06643843650817871\n",
      "rot_error: 0.06779257953166962\n",
      "rot_error: 0.06943551450967789\n",
      "rot_error: 0.0716489925980568\n",
      "rot_error: 3.9142892360687256\n",
      "rot_error: 3.599483013153076\n",
      "rot_error: 3.1846256256103516\n",
      "rot_error: 2.7263498306274414\n",
      "rot_error: 2.2641429901123047\n",
      "rot_error: 1.833085536956787\n",
      "rot_error: 1.4557685852050781\n",
      "rot_error: 1.140876293182373\n",
      "rot_error: 0.8806496858596802\n",
      "rot_error: 0.6724393367767334\n",
      "rot_error: 0.523173451423645\n",
      "rot_error: 0.44914016127586365\n",
      "rot_error: 0.40247464179992676\n",
      "rot_error: 0.3669135570526123\n",
      "rot_error: 0.3336999714374542\n",
      "rot_error: 0.3098737895488739\n",
      "rot_error: 0.2818436920642853\n",
      "rot_error: 0.2634034752845764\n",
      "rot_error: 0.24158544838428497\n",
      "rot_error: 0.22461412847042084\n",
      "rot_error: 0.20052899420261383\n",
      "rot_error: 0.17993158102035522\n",
      "rot_error: 0.16377829015254974\n",
      "rot_error: 0.14668075740337372\n",
      "rot_error: 0.13638383150100708\n",
      "rot_error: 0.12717141211032867\n",
      "rot_error: 0.12423114478588104\n",
      "rot_error: 0.11743678152561188\n",
      "rot_error: 0.10406996309757233\n",
      "rot_error: 0.09864017367362976\n",
      "rot_error: 0.08715301752090454\n",
      "rot_error: 0.08821457624435425\n",
      "rot_error: 0.08691631257534027\n",
      "rot_error: 0.07757404446601868\n",
      "rot_error: 0.06819351017475128\n",
      "rot_error: 0.06675761938095093\n",
      "rot_error: 0.06717076897621155\n",
      "rot_error: 0.06066546216607094\n",
      "rot_error: 0.06343145668506622\n",
      "rot_error: 0.05546516552567482\n",
      "rot_error: 0.05946516618132591\n",
      "rot_error: 0.06275428831577301\n",
      "rot_error: 0.058897871524095535\n",
      "rot_error: 0.06278495490550995\n",
      "rot_error: 0.06628331542015076\n",
      "rot_error: 0.0580318458378315\n",
      "rot_error: 0.05550394579768181\n",
      "rot_error: 0.05280836299061775\n",
      "rot_error: 0.056808363646268845\n",
      "rot_error: 0.053573813289403915\n",
      "rot_error: 0.055524375289678574\n",
      "rot_error: 0.049791064113378525\n",
      "rot_error: 0.05144064500927925\n",
      "rot_error: 0.04834001883864403\n",
      "rot_error: 0.04369476065039635\n",
      "rot_error: 0.039609625935554504\n",
      "rot_error: 0.04247063025832176\n",
      "rot_error: 0.04266431927680969\n",
      "rot_error: 0.04312684014439583\n",
      "rot_error: 0.03730183094739914\n",
      "rot_error: 0.04084094986319542\n",
      "rot_error: 0.035222988575696945\n",
      "rot_error: 0.03922298923134804\n",
      "rot_error: 0.04107953608036041\n",
      "rot_error: 0.03923605754971504\n",
      "rot_error: 0.043236058205366135\n",
      "rot_error: 0.03728931397199631\n",
      "rot_error: 0.033289313316345215\n",
      "rot_error: 0.029579129070043564\n",
      "rot_error: 0.033579129725694656\n",
      "rot_error: 0.0356842465698719\n",
      "rot_error: 0.03671423718333244\n",
      "rot_error: 0.040714237838983536\n",
      "rot_error: 0.04098694771528244\n",
      "rot_error: 0.03587128967046738\n",
      "rot_error: 0.03923927620053291\n",
      "rot_error: 0.038187894970178604\n",
      "rot_error: 0.03703821823000908\n",
      "rot_error: 0.037526074796915054\n",
      "rot_error: 0.03352607414126396\n",
      "rot_error: 0.03323901817202568\n",
      "rot_error: 0.032930295914411545\n",
      "rot_error: 0.031599994748830795\n",
      "rot_error: 0.03502422943711281\n",
      "rot_error: 0.032809045165777206\n",
      "rot_error: 0.0368090458214283\n",
      "rot_error: 0.03718138113617897\n",
      "rot_error: 0.04118138179183006\n",
      "rot_error: 0.045181382447481155\n",
      "rot_error: 0.04161030799150467\n",
      "rot_error: 0.04324740171432495\n",
      "rot_error: 0.044793374836444855\n",
      "rot_error: 0.0468222051858902\n",
      "rot_error: 0.049441780894994736\n",
      "rot_error: 0.04823968559503555\n",
      "rot_error: 0.046525679528713226\n",
      "rot_error: 0.04248908907175064\n",
      "rot_error: 0.04104544594883919\n",
      "rot_error: 0.03539593517780304\n",
      "rot_error: 0.031395938247442245\n",
      "rot_error: 1.6060972213745117\n",
      "rot_error: 1.4838883876800537\n",
      "rot_error: 1.323174238204956\n",
      "rot_error: 1.138798713684082\n",
      "rot_error: 0.9609396457672119\n",
      "rot_error: 0.7838277816772461\n",
      "rot_error: 0.6285234689712524\n",
      "rot_error: 0.502718448638916\n",
      "rot_error: 0.4048950672149658\n",
      "rot_error: 0.3216128945350647\n",
      "rot_error: 0.2661455571651459\n",
      "rot_error: 0.2321447879076004\n",
      "rot_error: 0.21859481930732727\n",
      "rot_error: 0.2005695104598999\n",
      "rot_error: 0.19238093495368958\n",
      "rot_error: 0.17552116513252258\n",
      "rot_error: 0.17181318998336792\n",
      "rot_error: 0.16849593818187714\n",
      "rot_error: 0.16152292490005493\n",
      "rot_error: 0.15211808681488037\n",
      "rot_error: 0.13937875628471375\n",
      "rot_error: 0.13708513975143433\n",
      "rot_error: 0.1323411762714386\n",
      "rot_error: 0.12157975137233734\n",
      "rot_error: 0.11810268461704254\n",
      "rot_error: 0.1087651252746582\n",
      "rot_error: 0.1006699949502945\n",
      "rot_error: 0.10029580444097519\n",
      "rot_error: 0.09900343418121338\n",
      "rot_error: 0.09461426734924316\n",
      "rot_error: 0.09395590424537659\n",
      "rot_error: 0.09482897818088531\n",
      "rot_error: 0.09882897883653641\n",
      "rot_error: 0.09650125354528427\n",
      "rot_error: 0.09846475720405579\n",
      "rot_error: 0.100731261074543\n",
      "rot_error: 0.10104399174451828\n",
      "rot_error: 0.10147327184677124\n",
      "rot_error: 0.10519865155220032\n",
      "rot_error: 0.1071196049451828\n",
      "rot_error: 0.09905444830656052\n",
      "rot_error: 0.09436491876840591\n",
      "rot_error: 0.09747074544429779\n",
      "rot_error: 0.09083328396081924\n",
      "rot_error: 0.09224842488765717\n",
      "rot_error: 0.09470066428184509\n",
      "rot_error: 0.08936594426631927\n",
      "rot_error: 0.08612613379955292\n",
      "rot_error: 0.08442935347557068\n",
      "rot_error: 0.08712472766637802\n",
      "rot_error: 0.08148409426212311\n",
      "rot_error: 0.0854841023683548\n",
      "rot_error: 0.08094142377376556\n",
      "rot_error: 0.0830298662185669\n",
      "rot_error: 0.08702985942363739\n",
      "rot_error: 0.08256170153617859\n",
      "rot_error: 0.0859326422214508\n",
      "rot_error: 0.08573634177446365\n",
      "rot_error: 0.08973634243011475\n",
      "rot_error: 0.08786439895629883\n",
      "rot_error: 0.08620697259902954\n",
      "rot_error: 0.0800589844584465\n",
      "rot_error: 0.08074917644262314\n",
      "rot_error: 0.08366824686527252\n",
      "rot_error: 0.0800580233335495\n",
      "rot_error: 0.07605801522731781\n",
      "rot_error: 0.07956575602293015\n",
      "rot_error: 0.07556575536727905\n",
      "rot_error: 0.07916700839996338\n",
      "rot_error: 0.07516701519489288\n",
      "rot_error: 0.07424898445606232\n",
      "rot_error: 0.07772432267665863\n",
      "rot_error: 0.08137194812297821\n",
      "rot_error: 0.08084030449390411\n",
      "rot_error: 0.0842708945274353\n",
      "rot_error: 0.07905182242393494\n",
      "rot_error: 0.08036792278289795\n",
      "rot_error: 0.08151630312204361\n",
      "rot_error: 0.07751630246639252\n",
      "rot_error: 0.08151630312204361\n",
      "rot_error: 0.0855163037776947\n",
      "rot_error: 0.08925052732229233\n",
      "rot_error: 0.08279818296432495\n",
      "rot_error: 0.08064566552639008\n",
      "rot_error: 0.08464565873146057\n",
      "rot_error: 0.08864566683769226\n",
      "rot_error: 0.08826418220996857\n",
      "rot_error: 0.08191046863794327\n",
      "rot_error: 0.08591046929359436\n",
      "rot_error: 0.08280320465564728\n",
      "rot_error: 0.08680321276187897\n",
      "rot_error: 0.09080320596694946\n",
      "rot_error: 0.08419559895992279\n",
      "rot_error: 0.0847916528582573\n",
      "rot_error: 0.08048748970031738\n",
      "rot_error: 0.07648749649524689\n",
      "rot_error: 0.07762239128351212\n",
      "rot_error: 0.07817074656486511\n",
      "rot_error: 0.07647033035755157\n",
      "rot_error: 0.0771327018737793\n",
      "Episode 10, Reward: -191.34, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "rot_error: 3.116135835647583\n",
      "rot_error: 2.8272266387939453\n",
      "rot_error: 2.5508532524108887\n",
      "rot_error: 2.286142349243164\n",
      "rot_error: 2.0437097549438477\n",
      "rot_error: 1.8243993520736694\n",
      "rot_error: 1.638867735862732\n",
      "rot_error: 1.4738212823867798\n",
      "rot_error: 1.3175641298294067\n",
      "rot_error: 1.1852370500564575\n",
      "rot_error: 1.0677822828292847\n",
      "rot_error: 0.9629431366920471\n",
      "rot_error: 0.8818442821502686\n",
      "rot_error: 0.8069317936897278\n",
      "rot_error: 0.7389240860939026\n",
      "rot_error: 0.6760146021842957\n",
      "rot_error: 0.6148737668991089\n",
      "rot_error: 0.5589625835418701\n",
      "rot_error: 0.5181228518486023\n",
      "rot_error: 0.47358956933021545\n",
      "rot_error: 0.43893834948539734\n",
      "rot_error: 0.41104552149772644\n",
      "rot_error: 0.3827533423900604\n",
      "rot_error: 0.36047905683517456\n",
      "rot_error: 0.34043222665786743\n",
      "rot_error: 0.31099003553390503\n",
      "rot_error: 0.29101330041885376\n",
      "rot_error: 0.27791303396224976\n",
      "rot_error: 0.25978848338127136\n",
      "rot_error: 0.2417648285627365\n",
      "rot_error: 0.2271641343832016\n",
      "rot_error: 0.22044877707958221\n",
      "rot_error: 0.20880939066410065\n",
      "rot_error: 0.20392949879169464\n",
      "rot_error: 0.19482919573783875\n",
      "rot_error: 0.1863936483860016\n",
      "rot_error: 0.17753639817237854\n",
      "rot_error: 0.16438382863998413\n",
      "rot_error: 0.1637861579656601\n",
      "rot_error: 0.16340859234333038\n",
      "rot_error: 0.1553211510181427\n",
      "rot_error: 0.14717018604278564\n",
      "rot_error: 0.13751505315303802\n",
      "rot_error: 0.13285481929779053\n",
      "rot_error: 0.13276821374893188\n",
      "rot_error: 0.12951961159706116\n",
      "rot_error: 0.13256870210170746\n",
      "rot_error: 0.1299026608467102\n",
      "rot_error: 0.12904317677021027\n",
      "rot_error: 0.12341617047786713\n",
      "rot_error: 0.12707561254501343\n",
      "rot_error: 0.12736240029335022\n",
      "rot_error: 0.13062721490859985\n",
      "rot_error: 0.12216554582118988\n",
      "rot_error: 0.11695383489131927\n",
      "rot_error: 0.12095382809638977\n",
      "rot_error: 0.12485949695110321\n",
      "rot_error: 0.1169746071100235\n",
      "rot_error: 0.11942556500434875\n",
      "rot_error: 0.11687599122524261\n",
      "rot_error: 0.12037308514118195\n",
      "rot_error: 0.12041178345680237\n",
      "rot_error: 0.11297164857387543\n",
      "rot_error: 0.1062755435705185\n",
      "rot_error: 0.1002490445971489\n",
      "rot_error: 0.10073994100093842\n",
      "rot_error: 0.10166710615158081\n",
      "rot_error: 0.1056671142578125\n",
      "rot_error: 0.10657908767461777\n",
      "rot_error: 0.11017461121082306\n",
      "rot_error: 0.11127716302871704\n",
      "rot_error: 0.112077996134758\n",
      "rot_error: 0.10655280202627182\n",
      "rot_error: 0.11055280268192291\n",
      "rot_error: 0.11020413041114807\n",
      "rot_error: 0.10428425669670105\n",
      "rot_error: 0.10828425735235214\n",
      "rot_error: 0.10205689072608948\n",
      "rot_error: 0.09818798303604126\n",
      "rot_error: 0.09728499501943588\n",
      "rot_error: 0.10128499567508698\n",
      "rot_error: 0.09814169257879257\n",
      "rot_error: 0.09414169192314148\n",
      "rot_error: 0.09458629041910172\n",
      "rot_error: 0.09734292328357697\n",
      "rot_error: 0.09621492028236389\n",
      "rot_error: 0.0922149270772934\n",
      "rot_error: 0.0924033597111702\n",
      "rot_error: 0.08908756822347641\n",
      "rot_error: 0.08657309412956238\n",
      "rot_error: 0.08563607931137085\n",
      "rot_error: 0.08669809997081757\n",
      "rot_error: 0.08620725572109222\n",
      "rot_error: 0.08548255264759064\n",
      "rot_error: 0.08225908875465393\n",
      "rot_error: 0.08310620486736298\n",
      "rot_error: 0.08472996205091476\n",
      "rot_error: 0.08144830167293549\n",
      "rot_error: 0.08147813379764557\n",
      "rot_error: 0.08547813445329666\n",
      "rot_error: 4.892336845397949\n",
      "rot_error: 4.479996204376221\n",
      "rot_error: 3.971696376800537\n",
      "rot_error: 3.4180355072021484\n",
      "rot_error: 2.867384433746338\n",
      "rot_error: 2.36476469039917\n",
      "rot_error: 1.9141710996627808\n",
      "rot_error: 1.5322299003601074\n",
      "rot_error: 1.2164530754089355\n",
      "rot_error: 0.9620165228843689\n",
      "rot_error: 0.773889422416687\n",
      "rot_error: 0.6714380383491516\n",
      "rot_error: 0.6039924621582031\n",
      "rot_error: 0.542664647102356\n",
      "rot_error: 0.4887176752090454\n",
      "rot_error: 0.44885361194610596\n",
      "rot_error: 0.40175074338912964\n",
      "rot_error: 0.3594110310077667\n",
      "rot_error: 0.32137331366539\n",
      "rot_error: 0.2984921932220459\n",
      "rot_error: 0.26937752962112427\n",
      "rot_error: 0.2516978979110718\n",
      "rot_error: 0.23578636348247528\n",
      "rot_error: 0.2164485603570938\n",
      "rot_error: 0.20045191049575806\n",
      "rot_error: 0.18100425601005554\n",
      "rot_error: 0.17208899557590485\n",
      "rot_error: 0.15741907060146332\n",
      "rot_error: 0.14854566752910614\n",
      "rot_error: 0.13978062570095062\n",
      "rot_error: 0.12876783311367035\n",
      "rot_error: 0.11956890672445297\n",
      "rot_error: 0.11576827615499496\n",
      "rot_error: 0.10764393955469131\n",
      "rot_error: 0.09666776657104492\n",
      "rot_error: 0.09337086230516434\n",
      "rot_error: 0.09329209476709366\n",
      "rot_error: 0.09322119504213333\n",
      "rot_error: 0.088302843272686\n",
      "rot_error: 0.08873087167739868\n",
      "rot_error: 0.08161874115467072\n",
      "rot_error: 0.07131517678499222\n",
      "rot_error: 0.06628004461526871\n",
      "rot_error: 0.06504922360181808\n",
      "rot_error: 0.06772295385599136\n",
      "rot_error: 0.07020897418260574\n",
      "rot_error: 0.07179716974496841\n",
      "rot_error: 0.07387576252222061\n",
      "rot_error: 0.07566940784454346\n",
      "rot_error: 0.07110211998224258\n",
      "rot_error: 0.06971298158168793\n",
      "rot_error: 0.07199999690055847\n",
      "rot_error: 0.06860772520303726\n",
      "rot_error: 0.05960526317358017\n",
      "rot_error: 0.05150304734706879\n",
      "rot_error: 0.052898138761520386\n",
      "rot_error: 0.05665592849254608\n",
      "rot_error: 0.052393898367881775\n",
      "rot_error: 0.0541873425245285\n",
      "rot_error: 0.05802692472934723\n",
      "rot_error: 0.05008254200220108\n",
      "rot_error: 0.05408254265785217\n",
      "rot_error: 0.04653260111808777\n",
      "rot_error: 0.04628952592611313\n",
      "rot_error: 0.04916316270828247\n",
      "rot_error: 0.05226970463991165\n",
      "rot_error: 0.052701354026794434\n",
      "rot_error: 0.0452895313501358\n",
      "rot_error: 0.0492895245552063\n",
      "rot_error: 0.05328952521085739\n",
      "rot_error: 0.04613321274518967\n",
      "rot_error: 0.04618385434150696\n",
      "rot_error: 0.05018385499715805\n",
      "rot_error: 0.04568111151456833\n",
      "rot_error: 0.043855562806129456\n",
      "rot_error: 0.039723239839076996\n",
      "rot_error: 0.04128114879131317\n",
      "rot_error: 0.03668186068534851\n",
      "rot_error: 0.03888797014951706\n",
      "rot_error: 0.04262975603342056\n",
      "rot_error: 0.0362250953912735\n",
      "rot_error: 0.03914906829595566\n",
      "rot_error: 0.033092476427555084\n",
      "rot_error: 0.03345305472612381\n",
      "rot_error: 0.02967500500380993\n",
      "rot_error: 0.028779560700058937\n",
      "rot_error: 0.029818786308169365\n",
      "rot_error: 0.02797642908990383\n",
      "rot_error: 0.02530314214527607\n",
      "rot_error: 0.022274794057011604\n",
      "rot_error: 0.018274793401360512\n",
      "rot_error: 0.021340468898415565\n",
      "rot_error: 0.023708144202828407\n",
      "rot_error: 0.020072968676686287\n",
      "rot_error: 0.021180571988224983\n",
      "rot_error: 0.024490920826792717\n",
      "rot_error: 0.02679300121963024\n",
      "rot_error: 0.027739470824599266\n",
      "rot_error: 0.030641617253422737\n",
      "rot_error: 0.02758082188665867\n",
      "rot_error: 1.3263698816299438\n",
      "rot_error: 1.2078423500061035\n",
      "rot_error: 1.0910437107086182\n",
      "rot_error: 0.989659309387207\n",
      "rot_error: 0.8844951391220093\n",
      "rot_error: 0.8004461526870728\n",
      "rot_error: 0.7137988209724426\n",
      "rot_error: 0.6453536748886108\n",
      "rot_error: 0.5883544683456421\n",
      "rot_error: 0.534913957118988\n",
      "rot_error: 0.4916019141674042\n",
      "rot_error: 0.44874292612075806\n",
      "rot_error: 0.41964930295944214\n",
      "rot_error: 0.38452839851379395\n",
      "rot_error: 0.3621819019317627\n",
      "rot_error: 0.3398038446903229\n",
      "rot_error: 0.31932535767555237\n",
      "rot_error: 0.30365610122680664\n",
      "rot_error: 0.2877070903778076\n",
      "rot_error: 0.2709825932979584\n",
      "rot_error: 0.24957989156246185\n",
      "rot_error: 0.240886390209198\n",
      "rot_error: 0.22444802522659302\n",
      "rot_error: 0.21647889912128448\n",
      "rot_error: 0.21109551191329956\n",
      "rot_error: 0.2029120773077011\n",
      "rot_error: 0.1937880963087082\n",
      "rot_error: 0.18396010994911194\n",
      "rot_error: 0.1818285882472992\n",
      "rot_error: 0.17168331146240234\n",
      "rot_error: 0.16084745526313782\n",
      "rot_error: 0.15353715419769287\n",
      "rot_error: 0.1476893275976181\n",
      "rot_error: 0.1377848982810974\n",
      "rot_error: 0.1402709037065506\n",
      "rot_error: 0.13618123531341553\n",
      "rot_error: 0.1353391408920288\n",
      "rot_error: 0.13633513450622559\n",
      "rot_error: 0.1275661289691925\n",
      "rot_error: 0.12493608891963959\n",
      "rot_error: 0.12870697677135468\n",
      "rot_error: 0.12516051530838013\n",
      "rot_error: 0.11985237896442413\n",
      "rot_error: 0.11803680658340454\n",
      "rot_error: 0.11109762638807297\n",
      "rot_error: 0.10919049382209778\n",
      "rot_error: 0.10998435318470001\n",
      "rot_error: 0.113082155585289\n",
      "rot_error: 0.10663843899965286\n",
      "rot_error: 0.11063843965530396\n",
      "rot_error: 0.11306217312812805\n",
      "rot_error: 0.11115975677967072\n",
      "rot_error: 0.11466826498508453\n",
      "rot_error: 0.10806593298912048\n",
      "rot_error: 0.10212384164333344\n",
      "rot_error: 0.10367633402347565\n",
      "rot_error: 0.10014642775058746\n",
      "rot_error: 0.09614642709493637\n",
      "rot_error: 0.10014642775058746\n",
      "rot_error: 0.10053351521492004\n",
      "rot_error: 0.10078368335962296\n",
      "rot_error: 0.1037607192993164\n",
      "rot_error: 0.10167950391769409\n",
      "rot_error: 0.10135549306869507\n",
      "rot_error: 0.10243289917707443\n",
      "rot_error: 0.09929007291793823\n",
      "rot_error: 0.09538230299949646\n",
      "rot_error: 0.096030592918396\n",
      "rot_error: 0.09673748910427094\n",
      "rot_error: 0.09552840888500214\n",
      "rot_error: 0.09443309903144836\n",
      "rot_error: 0.09676685929298401\n",
      "rot_error: 0.09276685118675232\n",
      "rot_error: 0.09302801638841629\n",
      "rot_error: 0.0890280157327652\n",
      "rot_error: 0.09100815653800964\n",
      "rot_error: 0.09500816464424133\n",
      "rot_error: 0.09900815784931183\n",
      "rot_error: 0.09857957065105438\n",
      "rot_error: 0.10257956385612488\n",
      "rot_error: 0.10360811650753021\n",
      "rot_error: 0.10760810971260071\n",
      "rot_error: 0.10171180218458176\n",
      "rot_error: 0.10571180284023285\n",
      "rot_error: 0.10574400424957275\n",
      "rot_error: 0.1028515174984932\n",
      "rot_error: 0.10176299512386322\n",
      "rot_error: 0.09776300191879272\n",
      "rot_error: 0.10176299512386322\n",
      "rot_error: 0.10315273702144623\n",
      "rot_error: 0.10715274512767792\n",
      "rot_error: 0.10306161642074585\n",
      "rot_error: 0.10241928696632385\n",
      "rot_error: 0.10265809297561646\n",
      "rot_error: 0.10183627903461456\n",
      "rot_error: 0.09783627837896347\n",
      "rot_error: 0.09821104258298874\n",
      "rot_error: 0.09936058521270752\n",
      "rot_error: 0.09960846602916718\n",
      "rot_error: 0.10360845923423767\n",
      "rot_error: 1.8444545269012451\n",
      "rot_error: 1.6494219303131104\n",
      "rot_error: 1.4969913959503174\n",
      "rot_error: 1.3813166618347168\n",
      "rot_error: 1.2964385747909546\n",
      "rot_error: 1.2175781726837158\n",
      "rot_error: 1.1539747714996338\n",
      "rot_error: 1.091600775718689\n",
      "rot_error: 1.0283615589141846\n",
      "rot_error: 0.9638934135437012\n",
      "rot_error: 0.8983149528503418\n",
      "rot_error: 0.8131723999977112\n",
      "rot_error: 0.7355053424835205\n",
      "rot_error: 0.6621957421302795\n",
      "rot_error: 0.6036238074302673\n",
      "rot_error: 0.5469884276390076\n",
      "rot_error: 0.4883591830730438\n",
      "rot_error: 0.4355803430080414\n",
      "rot_error: 0.388075590133667\n",
      "rot_error: 0.3567202091217041\n",
      "rot_error: 0.320137083530426\n",
      "rot_error: 0.28704148530960083\n",
      "rot_error: 0.25477835536003113\n",
      "rot_error: 0.2253521978855133\n",
      "rot_error: 0.20485135912895203\n",
      "rot_error: 0.18930530548095703\n",
      "rot_error: 0.17355063557624817\n",
      "rot_error: 0.1539124846458435\n",
      "rot_error: 0.13694223761558533\n",
      "rot_error: 0.12968039512634277\n",
      "rot_error: 0.12185505777597427\n",
      "rot_error: 0.11125365644693375\n",
      "rot_error: 0.10757995396852493\n",
      "rot_error: 0.09782392531633377\n",
      "rot_error: 0.09549318999052048\n",
      "rot_error: 0.09210460633039474\n",
      "rot_error: 0.08843467384576797\n",
      "rot_error: 0.08364677429199219\n",
      "rot_error: 0.07622504979372025\n",
      "rot_error: 0.06573201715946198\n",
      "rot_error: 0.056176766753196716\n",
      "rot_error: 0.05778238922357559\n",
      "rot_error: 0.051015712320804596\n",
      "rot_error: 0.04571050405502319\n",
      "rot_error: 0.04355994611978531\n",
      "rot_error: 0.03601572662591934\n",
      "rot_error: 0.03986581414937973\n",
      "rot_error: 0.03420306742191315\n",
      "rot_error: 0.03453635424375534\n",
      "rot_error: 0.03853438049554825\n",
      "rot_error: 0.04154449701309204\n",
      "rot_error: 0.04393526166677475\n",
      "rot_error: 0.04699338972568512\n",
      "rot_error: 0.047239430248737335\n",
      "rot_error: 0.03856714814901352\n",
      "rot_error: 0.033649250864982605\n",
      "rot_error: 0.02893044799566269\n",
      "rot_error: 0.03196479380130768\n",
      "rot_error: 0.02781694382429123\n",
      "rot_error: 0.029618576169013977\n",
      "rot_error: 0.022708378732204437\n",
      "rot_error: 0.02670837938785553\n",
      "rot_error: 0.020089201629161835\n",
      "rot_error: 0.01413194090127945\n",
      "rot_error: 0.010769091546535492\n",
      "rot_error: 0.00924326479434967\n",
      "rot_error: 0.005243264138698578\n",
      "rot_error: 0.003214530646800995\n",
      "rot_error: 0.007214531302452087\n",
      "rot_error: 0.006091959774494171\n",
      "rot_error: 0.006238836795091629\n",
      "rot_error: 0.008545376360416412\n",
      "rot_error: 0.006987523287534714\n",
      "rot_error: 0.008820448070764542\n",
      "rot_error: 0.012029074132442474\n",
      "rot_error: 0.016029074788093567\n",
      "rot_error: 0.02002907544374466\n",
      "rot_error: 0.017648454755544662\n",
      "rot_error: 0.013988625258207321\n",
      "rot_error: 0.009988624602556229\n",
      "rot_error: 0.010707158595323563\n",
      "rot_error: 0.009353399276733398\n",
      "rot_error: 0.011301781982183456\n",
      "rot_error: 0.007301785051822662\n",
      "rot_error: 0.011301781982183456\n",
      "rot_error: 0.013501480221748352\n",
      "rot_error: 0.011525377631187439\n",
      "rot_error: 0.01406892016530037\n",
      "rot_error: 0.014950025826692581\n",
      "rot_error: 0.010950025171041489\n",
      "rot_error: 0.009492520242929459\n",
      "rot_error: 0.009732592850923538\n",
      "rot_error: 0.005732592195272446\n",
      "rot_error: 0.009580645710229874\n",
      "rot_error: 0.013580642640590668\n",
      "rot_error: 0.010990876704454422\n",
      "rot_error: 0.014561712741851807\n",
      "rot_error: 0.016839411109685898\n",
      "rot_error: 0.012839410454034805\n",
      "rot_error: 0.01403944194316864\n",
      "rot_error: 3.9235620498657227\n",
      "rot_error: 3.620035171508789\n",
      "rot_error: 3.1881039142608643\n",
      "rot_error: 2.6971094608306885\n",
      "rot_error: 2.2137436866760254\n",
      "rot_error: 1.764978051185608\n",
      "rot_error: 1.3648591041564941\n",
      "rot_error: 1.0205776691436768\n",
      "rot_error: 0.7421467304229736\n",
      "rot_error: 0.533252477645874\n",
      "rot_error: 0.3739560544490814\n",
      "rot_error: 0.31350868940353394\n",
      "rot_error: 0.2752862870693207\n",
      "rot_error: 0.25361737608909607\n",
      "rot_error: 0.23301491141319275\n",
      "rot_error: 0.2081586718559265\n",
      "rot_error: 0.19411154091358185\n",
      "rot_error: 0.17534777522087097\n",
      "rot_error: 0.15869754552841187\n",
      "rot_error: 0.15160006284713745\n",
      "rot_error: 0.14521388709545135\n",
      "rot_error: 0.13304255902767181\n",
      "rot_error: 0.11921165138483047\n",
      "rot_error: 0.11056281626224518\n",
      "rot_error: 0.10398989170789719\n",
      "rot_error: 0.0931432694196701\n",
      "rot_error: 0.0886894166469574\n",
      "rot_error: 0.08743426203727722\n",
      "rot_error: 0.08496598899364471\n",
      "rot_error: 0.08043870329856873\n",
      "rot_error: 0.08031322062015533\n",
      "rot_error: 0.08105640113353729\n",
      "rot_error: 0.0713747888803482\n",
      "rot_error: 0.06161182001233101\n",
      "rot_error: 0.059835147112607956\n",
      "rot_error: 0.060883644968271255\n",
      "rot_error: 0.06237337365746498\n",
      "rot_error: 0.06194266304373741\n",
      "rot_error: 0.05344532057642937\n",
      "rot_error: 0.052297625690698624\n",
      "rot_error: 0.049429845064878464\n",
      "rot_error: 0.053261373192071915\n",
      "rot_error: 0.047746654599905014\n",
      "rot_error: 0.048785630613565445\n",
      "rot_error: 0.050422873347997665\n",
      "rot_error: 0.04643803462386131\n",
      "rot_error: 0.03916874900460243\n",
      "rot_error: 0.0376957468688488\n",
      "rot_error: 0.03685412183403969\n",
      "rot_error: 0.04085412248969078\n",
      "rot_error: 0.034143220633268356\n",
      "rot_error: 0.03408724069595337\n",
      "rot_error: 0.0321098193526268\n",
      "rot_error: 0.03178277984261513\n",
      "rot_error: 0.028747037053108215\n",
      "rot_error: 0.027102358639240265\n",
      "rot_error: 0.0265534408390522\n",
      "rot_error: 0.026166770607233047\n",
      "rot_error: 0.02710435539484024\n",
      "rot_error: 0.025935456156730652\n",
      "rot_error: 0.0285775326192379\n",
      "rot_error: 0.025924772024154663\n",
      "rot_error: 0.02987229824066162\n",
      "rot_error: 0.03087681531906128\n",
      "rot_error: 0.030782777816057205\n",
      "rot_error: 0.030673902481794357\n",
      "rot_error: 0.030771568417549133\n",
      "rot_error: 0.034771569073200226\n",
      "rot_error: 0.03877157345414162\n",
      "rot_error: 0.039698999375104904\n",
      "rot_error: 0.0436989925801754\n",
      "rot_error: 0.04466627165675163\n",
      "rot_error: 0.04412452504038811\n",
      "rot_error: 0.0481245256960392\n",
      "rot_error: 0.0435207299888134\n",
      "rot_error: 0.046246740967035294\n",
      "rot_error: 0.048876386135816574\n",
      "rot_error: 0.049436185508966446\n",
      "rot_error: 0.04383915290236473\n",
      "rot_error: 0.04393220320343971\n",
      "rot_error: 0.03906598314642906\n",
      "rot_error: 0.03927523270249367\n",
      "rot_error: 0.03877817466855049\n",
      "rot_error: 0.03346414491534233\n",
      "rot_error: 0.028281349688768387\n",
      "rot_error: 0.025823578238487244\n",
      "rot_error: 0.027683883905410767\n",
      "rot_error: 0.03027883544564247\n",
      "rot_error: 0.027559082955121994\n",
      "rot_error: 0.025452766567468643\n",
      "rot_error: 0.027682658284902573\n",
      "rot_error: 0.02368265762925148\n",
      "rot_error: 0.019682656973600388\n",
      "rot_error: 0.0159185528755188\n",
      "rot_error: 0.017807550728321075\n",
      "rot_error: 0.021807551383972168\n",
      "rot_error: 0.02105099707841873\n",
      "rot_error: 0.02312421053647995\n",
      "rot_error: 0.027124211192131042\n",
      "rot_error: 0.031124211847782135\n",
      "rot_error: 4.602579593658447\n",
      "rot_error: 4.195550918579102\n",
      "rot_error: 3.740335464477539\n",
      "rot_error: 3.262984037399292\n",
      "rot_error: 2.8090014457702637\n",
      "rot_error: 2.387331485748291\n",
      "rot_error: 2.0088906288146973\n",
      "rot_error: 1.6921509504318237\n",
      "rot_error: 1.417281985282898\n",
      "rot_error: 1.2007408142089844\n",
      "rot_error: 1.0242371559143066\n",
      "rot_error: 0.9071751236915588\n",
      "rot_error: 0.8108230829238892\n",
      "rot_error: 0.728283703327179\n",
      "rot_error: 0.6576358079910278\n",
      "rot_error: 0.6005882024765015\n",
      "rot_error: 0.5522350072860718\n",
      "rot_error: 0.5087521076202393\n",
      "rot_error: 0.4665205478668213\n",
      "rot_error: 0.4202229678630829\n",
      "rot_error: 0.380931556224823\n",
      "rot_error: 0.35300424695014954\n",
      "rot_error: 0.32793545722961426\n",
      "rot_error: 0.2987370193004608\n",
      "rot_error: 0.270449697971344\n",
      "rot_error: 0.2551605701446533\n",
      "rot_error: 0.23598673939704895\n",
      "rot_error: 0.22414390742778778\n",
      "rot_error: 0.2114863246679306\n",
      "rot_error: 0.19069352746009827\n",
      "rot_error: 0.17198002338409424\n",
      "rot_error: 0.16653785109519958\n",
      "rot_error: 0.15023991465568542\n",
      "rot_error: 0.14697176218032837\n",
      "rot_error: 0.13670429587364197\n",
      "rot_error: 0.12338970601558685\n",
      "rot_error: 0.11601261794567108\n",
      "rot_error: 0.10660026967525482\n",
      "rot_error: 0.10570579767227173\n",
      "rot_error: 0.09549105167388916\n",
      "rot_error: 0.09438715875148773\n",
      "rot_error: 0.09286421537399292\n",
      "rot_error: 0.08393363654613495\n",
      "rot_error: 0.08239008486270905\n",
      "rot_error: 0.0801512748003006\n",
      "rot_error: 0.08107835054397583\n",
      "rot_error: 0.07814250886440277\n",
      "rot_error: 0.080532968044281\n",
      "rot_error: 0.0728355199098587\n",
      "rot_error: 0.07409009337425232\n",
      "rot_error: 0.07809008657932281\n",
      "rot_error: 0.07328784465789795\n",
      "rot_error: 0.06631490588188171\n",
      "rot_error: 0.06356772780418396\n",
      "rot_error: 0.06422385573387146\n",
      "rot_error: 0.05815731734037399\n",
      "rot_error: 0.0541573166847229\n",
      "rot_error: 0.05276038497686386\n",
      "rot_error: 0.056760385632514954\n",
      "rot_error: 0.05667906627058983\n",
      "rot_error: 0.057885367423295975\n",
      "rot_error: 0.06188536807894707\n",
      "rot_error: 0.06156937777996063\n",
      "rot_error: 0.0598280131816864\n",
      "rot_error: 0.05740636959671974\n",
      "rot_error: 0.05700245127081871\n",
      "rot_error: 0.05567188933491707\n",
      "rot_error: 0.055128660053014755\n",
      "rot_error: 0.05133168771862984\n",
      "rot_error: 0.04932449385523796\n",
      "rot_error: 0.05332449451088905\n",
      "rot_error: 0.04932449385523796\n",
      "rot_error: 0.045793674886226654\n",
      "rot_error: 0.04551934823393822\n",
      "rot_error: 0.044530123472213745\n",
      "rot_error: 0.04372598975896835\n",
      "rot_error: 0.047725990414619446\n",
      "rot_error: 0.04372598975896835\n",
      "rot_error: 0.044253841042518616\n",
      "rot_error: 0.046587321907281876\n",
      "rot_error: 0.05058732256293297\n",
      "rot_error: 0.05085926130414009\n",
      "rot_error: 0.0519406683743\n",
      "rot_error: 0.05154840275645256\n",
      "rot_error: 0.04998689889907837\n",
      "rot_error: 0.04978344216942787\n",
      "rot_error: 0.05252508819103241\n",
      "rot_error: 0.05039331316947937\n",
      "rot_error: 0.046787917613983154\n",
      "rot_error: 0.047621939331293106\n",
      "rot_error: 0.043621938675642014\n",
      "rot_error: 0.045716430991888046\n",
      "rot_error: 0.045167334377765656\n",
      "rot_error: 0.04916733503341675\n",
      "rot_error: 0.04952766001224518\n",
      "rot_error: 0.045661695301532745\n",
      "rot_error: 0.04869580268859863\n",
      "rot_error: 0.052695803344249725\n",
      "rot_error: 0.05051132291555405\n",
      "rot_error: 0.05451132357120514\n",
      "rot_error: 3.6843347549438477\n",
      "rot_error: 3.3559436798095703\n",
      "rot_error: 3.0005455017089844\n",
      "rot_error: 2.6402103900909424\n",
      "rot_error: 2.2858591079711914\n",
      "rot_error: 1.9607288837432861\n",
      "rot_error: 1.6758027076721191\n",
      "rot_error: 1.425217628479004\n",
      "rot_error: 1.2232389450073242\n",
      "rot_error: 1.0559409856796265\n",
      "rot_error: 0.9118854999542236\n",
      "rot_error: 0.8178690075874329\n",
      "rot_error: 0.734001636505127\n",
      "rot_error: 0.6722717881202698\n",
      "rot_error: 0.6147427558898926\n",
      "rot_error: 0.5553909540176392\n",
      "rot_error: 0.5131738185882568\n",
      "rot_error: 0.4638019800186157\n",
      "rot_error: 0.42404916882514954\n",
      "rot_error: 0.39404919743537903\n",
      "rot_error: 0.35680025815963745\n",
      "rot_error: 0.33447593450546265\n",
      "rot_error: 0.3141317665576935\n",
      "rot_error: 0.29607439041137695\n",
      "rot_error: 0.27644509077072144\n",
      "rot_error: 0.2507563829421997\n",
      "rot_error: 0.23178960382938385\n",
      "rot_error: 0.22088249027729034\n",
      "rot_error: 0.21215005218982697\n",
      "rot_error: 0.19289085268974304\n",
      "rot_error: 0.1835647076368332\n",
      "rot_error: 0.17856404185295105\n",
      "rot_error: 0.1719769835472107\n",
      "rot_error: 0.15904028713703156\n",
      "rot_error: 0.15649206936359406\n",
      "rot_error: 0.14334823191165924\n",
      "rot_error: 0.14236921072006226\n",
      "rot_error: 0.13673585653305054\n",
      "rot_error: 0.12677723169326782\n",
      "rot_error: 0.12351430952548981\n",
      "rot_error: 0.12026488780975342\n",
      "rot_error: 0.1206980049610138\n",
      "rot_error: 0.11781564354896545\n",
      "rot_error: 0.1126178577542305\n",
      "rot_error: 0.11471188068389893\n",
      "rot_error: 0.10783694684505463\n",
      "rot_error: 0.09900905936956406\n",
      "rot_error: 0.09680813550949097\n",
      "rot_error: 0.09208893030881882\n",
      "rot_error: 0.09196841716766357\n",
      "rot_error: 0.09477916359901428\n",
      "rot_error: 0.09747731685638428\n",
      "rot_error: 0.10108538717031479\n",
      "rot_error: 0.10179613530635834\n",
      "rot_error: 0.10081689059734344\n",
      "rot_error: 0.09819131344556808\n",
      "rot_error: 0.09507359564304352\n",
      "rot_error: 0.08815902471542358\n",
      "rot_error: 0.09215902537107468\n",
      "rot_error: 0.08994640409946442\n",
      "rot_error: 0.08967425674200058\n",
      "rot_error: 0.09006966650485992\n",
      "rot_error: 0.09406966716051102\n",
      "rot_error: 0.09269435703754425\n",
      "rot_error: 0.08538072556257248\n",
      "rot_error: 0.08758396655321121\n",
      "rot_error: 0.09118124097585678\n",
      "rot_error: 0.08958032727241516\n",
      "rot_error: 0.09358032792806625\n",
      "rot_error: 0.09095698595046997\n",
      "rot_error: 0.09495698660612106\n",
      "rot_error: 0.08896839618682861\n",
      "rot_error: 0.0929683968424797\n",
      "rot_error: 0.09080512821674347\n",
      "rot_error: 0.09480512887239456\n",
      "rot_error: 0.08728041499853134\n",
      "rot_error: 0.09030444920063019\n",
      "rot_error: 0.08528086543083191\n",
      "rot_error: 0.08753621578216553\n",
      "rot_error: 0.09153621643781662\n",
      "rot_error: 0.0910334512591362\n",
      "rot_error: 0.08969126641750336\n",
      "rot_error: 0.09224540740251541\n",
      "rot_error: 0.09261804819107056\n",
      "rot_error: 0.09132596105337143\n",
      "rot_error: 0.09017989784479141\n",
      "rot_error: 0.09354601800441742\n",
      "rot_error: 0.09309219568967819\n",
      "rot_error: 0.08962300419807434\n",
      "rot_error: 0.08768214285373688\n",
      "rot_error: 0.08104810863733292\n",
      "rot_error: 0.0821424275636673\n",
      "rot_error: 0.08178231865167618\n",
      "rot_error: 0.0847419872879982\n",
      "rot_error: 0.0822572335600853\n",
      "rot_error: 0.08097441494464874\n",
      "rot_error: 0.08244872093200684\n",
      "rot_error: 0.07615965604782104\n",
      "rot_error: 0.07806587219238281\n",
      "rot_error: 0.07536142319440842\n",
      "rot_error: 1.675004482269287\n",
      "rot_error: 1.4928133487701416\n",
      "rot_error: 1.3659107685089111\n",
      "rot_error: 1.2852444648742676\n",
      "rot_error: 1.2219955921173096\n",
      "rot_error: 1.1733959913253784\n",
      "rot_error: 1.1213963031768799\n",
      "rot_error: 1.0734765529632568\n",
      "rot_error: 1.0230858325958252\n",
      "rot_error: 0.9658070802688599\n",
      "rot_error: 0.8969070315361023\n",
      "rot_error: 0.8149425983428955\n",
      "rot_error: 0.7440918684005737\n",
      "rot_error: 0.6720998287200928\n",
      "rot_error: 0.6130642890930176\n",
      "rot_error: 0.5597586035728455\n",
      "rot_error: 0.5003310441970825\n",
      "rot_error: 0.45823031663894653\n",
      "rot_error: 0.41256603598594666\n",
      "rot_error: 0.3761778473854065\n",
      "rot_error: 0.33528876304626465\n",
      "rot_error: 0.3075878620147705\n",
      "rot_error: 0.2794782519340515\n",
      "rot_error: 0.2581295073032379\n",
      "rot_error: 0.2310137152671814\n",
      "rot_error: 0.21403220295906067\n",
      "rot_error: 0.19639497995376587\n",
      "rot_error: 0.1759699583053589\n",
      "rot_error: 0.15506479144096375\n",
      "rot_error: 0.14287498593330383\n",
      "rot_error: 0.13651296496391296\n",
      "rot_error: 0.12729495763778687\n",
      "rot_error: 0.11315276473760605\n",
      "rot_error: 0.10976295918226242\n",
      "rot_error: 0.09675591439008713\n",
      "rot_error: 0.08360578864812851\n",
      "rot_error: 0.07811158895492554\n",
      "rot_error: 0.07194177061319351\n",
      "rot_error: 0.06933823972940445\n",
      "rot_error: 0.06249336898326874\n",
      "rot_error: 0.06219424307346344\n",
      "rot_error: 0.05872722715139389\n",
      "rot_error: 0.05413033068180084\n",
      "rot_error: 0.05007468909025192\n",
      "rot_error: 0.041986554861068726\n",
      "rot_error: 0.03946361690759659\n",
      "rot_error: 0.03316550701856613\n",
      "rot_error: 0.03659304231405258\n",
      "rot_error: 0.030741795897483826\n",
      "rot_error: 0.02420363947749138\n",
      "rot_error: 0.027320634573698044\n",
      "rot_error: 0.03132063150405884\n",
      "rot_error: 0.026984911412000656\n",
      "rot_error: 0.030704714357852936\n",
      "rot_error: 0.029121652245521545\n",
      "rot_error: 0.023886531591415405\n",
      "rot_error: 0.027886532247066498\n",
      "rot_error: 0.022116437554359436\n",
      "rot_error: 0.020185161381959915\n",
      "rot_error: 0.023025140166282654\n",
      "rot_error: 0.027025140821933746\n",
      "rot_error: 0.03102514147758484\n",
      "rot_error: 0.031163357198238373\n",
      "rot_error: 0.027458295226097107\n",
      "rot_error: 0.021253928542137146\n",
      "rot_error: 0.017253927886486053\n",
      "rot_error: 0.013253927230834961\n",
      "rot_error: 0.009253926575183868\n",
      "rot_error: 0.013253927230834961\n",
      "rot_error: 0.010302208364009857\n",
      "rot_error: 0.010201949626207352\n",
      "rot_error: 0.007810164242982864\n",
      "rot_error: 0.01166907325387001\n",
      "rot_error: 0.015669073909521103\n",
      "rot_error: 0.019064132124185562\n",
      "rot_error: 0.017377592623233795\n",
      "rot_error: 0.019580762833356857\n",
      "rot_error: 0.02358076348900795\n",
      "rot_error: 0.02091936022043228\n",
      "rot_error: 0.020006034523248672\n",
      "rot_error: 0.019432123750448227\n",
      "rot_error: 0.018677659332752228\n",
      "rot_error: 0.020973369479179382\n",
      "rot_error: 0.021365564316511154\n",
      "rot_error: 0.021446537226438522\n",
      "rot_error: 0.022899627685546875\n",
      "rot_error: 0.02273595705628395\n",
      "rot_error: 0.01703854277729988\n",
      "rot_error: 0.016262829303741455\n",
      "rot_error: 0.014949452131986618\n",
      "rot_error: 0.015066016465425491\n",
      "rot_error: 0.011066015809774399\n",
      "rot_error: 0.013548057526350021\n",
      "rot_error: 0.009548060595989227\n",
      "rot_error: 0.012312032282352448\n",
      "rot_error: 0.008312031626701355\n",
      "rot_error: 0.00842767208814621\n",
      "rot_error: 0.005715522915124893\n",
      "rot_error: 0.005168240517377853\n",
      "rot_error: 0.009168237447738647\n",
      "rot_error: 1.5880954265594482\n",
      "rot_error: 1.4990363121032715\n",
      "rot_error: 1.2765777111053467\n",
      "rot_error: 0.9855569005012512\n",
      "rot_error: 0.6728621125221252\n",
      "rot_error: 0.3768613934516907\n",
      "rot_error: 0.12907707691192627\n",
      "rot_error: 0.07949137687683105\n",
      "rot_error: 0.23768946528434753\n",
      "rot_error: 0.3540172576904297\n",
      "rot_error: 0.4212915301322937\n",
      "rot_error: 0.4211515486240387\n",
      "rot_error: 0.38934409618377686\n",
      "rot_error: 0.3578956127166748\n",
      "rot_error: 0.32441848516464233\n",
      "rot_error: 0.29372695088386536\n",
      "rot_error: 0.2756904363632202\n",
      "rot_error: 0.24972616136074066\n",
      "rot_error: 0.23332646489143372\n",
      "rot_error: 0.2116677165031433\n",
      "rot_error: 0.19200792908668518\n",
      "rot_error: 0.17643888294696808\n",
      "rot_error: 0.16410084068775177\n",
      "rot_error: 0.15150098502635956\n",
      "rot_error: 0.13985887169837952\n",
      "rot_error: 0.13424444198608398\n",
      "rot_error: 0.13372637331485748\n",
      "rot_error: 0.12969836592674255\n",
      "rot_error: 0.11823488026857376\n",
      "rot_error: 0.10791775584220886\n",
      "rot_error: 0.1001608744263649\n",
      "rot_error: 0.09536189585924149\n",
      "rot_error: 0.08733206987380981\n",
      "rot_error: 0.0913122370839119\n",
      "rot_error: 0.08958999067544937\n",
      "rot_error: 0.08213736116886139\n",
      "rot_error: 0.0760774314403534\n",
      "rot_error: 0.06997606158256531\n",
      "rot_error: 0.07197287678718567\n",
      "rot_error: 0.07357463985681534\n",
      "rot_error: 0.07672807574272156\n",
      "rot_error: 0.07056163251399994\n",
      "rot_error: 0.07310657203197479\n",
      "rot_error: 0.06813625991344452\n",
      "rot_error: 0.07213626801967621\n",
      "rot_error: 0.06769829243421555\n",
      "rot_error: 0.07169829308986664\n",
      "rot_error: 0.06769829243421555\n",
      "rot_error: 0.06369829177856445\n",
      "rot_error: 0.05969829484820366\n",
      "rot_error: 0.05731115862727165\n",
      "rot_error: 0.05331115797162056\n",
      "rot_error: 0.05046660080552101\n",
      "rot_error: 0.05385821312665939\n",
      "rot_error: 0.052086468786001205\n",
      "rot_error: 0.0560864694416523\n",
      "rot_error: 0.06008646637201309\n",
      "rot_error: 0.06408646702766418\n",
      "rot_error: 0.06794319301843643\n",
      "rot_error: 0.06394319236278534\n",
      "rot_error: 0.06794319301843643\n",
      "rot_error: 0.06986162811517715\n",
      "rot_error: 0.07386162877082825\n",
      "rot_error: 0.07045957446098328\n",
      "rot_error: 0.0721748098731041\n",
      "rot_error: 0.07338104397058487\n",
      "rot_error: 0.07679373025894165\n",
      "rot_error: 0.07062071561813354\n",
      "rot_error: 0.06662072241306305\n",
      "rot_error: 0.06444364041090012\n",
      "rot_error: 0.06316489726305008\n",
      "rot_error: 0.05984305962920189\n",
      "rot_error: 0.0606270357966423\n",
      "rot_error: 0.057209599763154984\n",
      "rot_error: 0.05661953613162041\n",
      "rot_error: 0.05819379538297653\n",
      "rot_error: 0.05692855268716812\n",
      "rot_error: 0.05292855203151703\n",
      "rot_error: 0.048928551375865936\n",
      "rot_error: 0.04539419710636139\n",
      "rot_error: 0.04880334064364433\n",
      "rot_error: 0.052033476531505585\n",
      "rot_error: 0.05603347718715668\n",
      "rot_error: 0.05437801405787468\n",
      "rot_error: 0.05037801340222359\n",
      "rot_error: 0.05437801405787468\n",
      "rot_error: 0.055723559111356735\n",
      "rot_error: 0.05972355976700783\n",
      "rot_error: 0.05991312488913536\n",
      "rot_error: 0.06391312181949615\n",
      "rot_error: 0.060597456991672516\n",
      "rot_error: 0.05862164869904518\n",
      "rot_error: 0.05934799462556839\n",
      "rot_error: 0.05628898739814758\n",
      "rot_error: 0.05228898674249649\n",
      "rot_error: 0.053550951182842255\n",
      "rot_error: 0.053168196231126785\n",
      "rot_error: 0.04916819557547569\n",
      "rot_error: 0.05211383104324341\n",
      "rot_error: 0.04865754768252373\n",
      "rot_error: 4.778032302856445\n",
      "rot_error: 4.355311393737793\n",
      "rot_error: 3.872755527496338\n",
      "rot_error: 3.387057065963745\n",
      "rot_error: 2.911151885986328\n",
      "rot_error: 2.481065273284912\n",
      "rot_error: 2.090217113494873\n",
      "rot_error: 1.7554616928100586\n",
      "rot_error: 1.4693483114242554\n",
      "rot_error: 1.2338844537734985\n",
      "rot_error: 1.0476651191711426\n",
      "rot_error: 0.9283434748649597\n",
      "rot_error: 0.8295987248420715\n",
      "rot_error: 0.7453266382217407\n",
      "rot_error: 0.6762628555297852\n",
      "rot_error: 0.6156461238861084\n",
      "rot_error: 0.565661609172821\n",
      "rot_error: 0.5200026035308838\n",
      "rot_error: 0.4698486924171448\n",
      "rot_error: 0.43397870659828186\n",
      "rot_error: 0.3957097828388214\n",
      "rot_error: 0.36777034401893616\n",
      "rot_error: 0.3312249183654785\n",
      "rot_error: 0.3015689551830292\n",
      "rot_error: 0.2795036733150482\n",
      "rot_error: 0.2589786946773529\n",
      "rot_error: 0.2333124876022339\n",
      "rot_error: 0.21764518320560455\n",
      "rot_error: 0.20216642320156097\n",
      "rot_error: 0.1821814477443695\n",
      "rot_error: 0.1641949564218521\n",
      "rot_error: 0.1483161896467209\n",
      "rot_error: 0.14511623978614807\n",
      "rot_error: 0.13856764137744904\n",
      "rot_error: 0.12494254112243652\n",
      "rot_error: 0.11267995089292526\n",
      "rot_error: 0.10771194845438004\n",
      "rot_error: 0.10217384994029999\n",
      "rot_error: 0.10293982923030853\n",
      "rot_error: 0.10427750647068024\n",
      "rot_error: 0.09408141672611237\n",
      "rot_error: 0.08490493893623352\n",
      "rot_error: 0.0880461111664772\n",
      "rot_error: 0.08874764293432236\n",
      "rot_error: 0.08685409277677536\n",
      "rot_error: 0.0786442682147026\n",
      "rot_error: 0.08098728209733963\n",
      "rot_error: 0.08412983268499374\n",
      "rot_error: 0.08507230877876282\n",
      "rot_error: 0.07888545840978622\n",
      "rot_error: 0.08015348017215729\n",
      "rot_error: 0.07637852430343628\n",
      "rot_error: 0.06897233426570892\n",
      "rot_error: 0.06988727301359177\n",
      "rot_error: 0.06973230093717575\n",
      "rot_error: 0.06791459769010544\n",
      "rot_error: 0.06161117926239967\n",
      "rot_error: 0.05720909684896469\n",
      "rot_error: 0.05881360173225403\n",
      "rot_error: 0.05954840034246445\n",
      "rot_error: 0.058907900005578995\n",
      "rot_error: 0.0549078993499279\n",
      "rot_error: 0.058907900005578995\n",
      "rot_error: 0.06016329675912857\n",
      "rot_error: 0.057240936905145645\n",
      "rot_error: 0.05456216633319855\n",
      "rot_error: 0.05594273656606674\n",
      "rot_error: 0.059942737221717834\n",
      "rot_error: 0.06394273042678833\n",
      "rot_error: 0.05865771695971489\n",
      "rot_error: 0.05939843878149986\n",
      "rot_error: 0.056026995182037354\n",
      "rot_error: 0.05202699452638626\n",
      "rot_error: 0.05245504900813103\n",
      "rot_error: 0.05399834364652634\n",
      "rot_error: 0.05799834057688713\n",
      "rot_error: 0.05399834364652634\n",
      "rot_error: 0.05799834057688713\n",
      "rot_error: 0.05845942348241806\n",
      "rot_error: 0.06022775173187256\n",
      "rot_error: 0.0639001727104187\n",
      "rot_error: 0.06438367813825607\n",
      "rot_error: 0.06610234081745148\n",
      "rot_error: 0.06896360963582993\n",
      "rot_error: 0.07296361029148102\n",
      "rot_error: 0.07293685525655746\n",
      "rot_error: 0.07693685591220856\n",
      "rot_error: 0.06947483122348785\n",
      "rot_error: 0.06275901198387146\n",
      "rot_error: 0.06675900518894196\n",
      "rot_error: 0.06748634576797485\n",
      "rot_error: 0.06096937134861946\n",
      "rot_error: 0.05879783630371094\n",
      "rot_error: 0.05851951986551285\n",
      "rot_error: 0.06056622788310051\n",
      "rot_error: 0.0547412671148777\n",
      "rot_error: 0.05141393840312958\n",
      "rot_error: 0.05143671855330467\n",
      "rot_error: 0.05501808598637581\n",
      "rot_error: 0.0590180829167366\n",
      "Episode 20, Reward: -315.59, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "rot_error: 1.9111576080322266\n",
      "rot_error: 1.7968641519546509\n",
      "rot_error: 1.5345039367675781\n",
      "rot_error: 1.1980504989624023\n",
      "rot_error: 0.8355768322944641\n",
      "rot_error: 0.4972102642059326\n",
      "rot_error: 0.2078542709350586\n",
      "rot_error: 0.031377434730529785\n",
      "rot_error: 0.21123427152633667\n",
      "rot_error: 0.3486027717590332\n",
      "rot_error: 0.43041443824768066\n",
      "rot_error: 0.4302024245262146\n",
      "rot_error: 0.41108089685440063\n",
      "rot_error: 0.3760988414287567\n",
      "rot_error: 0.35190606117248535\n",
      "rot_error: 0.3232811391353607\n",
      "rot_error: 0.3049296736717224\n",
      "rot_error: 0.2883072793483734\n",
      "rot_error: 0.27160459756851196\n",
      "rot_error: 0.25833919644355774\n",
      "rot_error: 0.2463986873626709\n",
      "rot_error: 0.23266637325286865\n",
      "rot_error: 0.2173728495836258\n",
      "rot_error: 0.20952831208705902\n",
      "rot_error: 0.19106818735599518\n",
      "rot_error: 0.17848548293113708\n",
      "rot_error: 0.17381803691387177\n",
      "rot_error: 0.15892894566059113\n",
      "rot_error: 0.14895474910736084\n",
      "rot_error: 0.1473575085401535\n",
      "rot_error: 0.14651447534561157\n",
      "rot_error: 0.13435573875904083\n",
      "rot_error: 0.12341288477182388\n",
      "rot_error: 0.12496431916952133\n",
      "rot_error: 0.11496060341596603\n",
      "rot_error: 0.10595725476741791\n",
      "rot_error: 0.10784290730953217\n",
      "rot_error: 0.10921353846788406\n",
      "rot_error: 0.11218490451574326\n",
      "rot_error: 0.10957635194063187\n",
      "rot_error: 0.10111143440008163\n",
      "rot_error: 0.09942107647657394\n",
      "rot_error: 0.0944029837846756\n",
      "rot_error: 0.0874553993344307\n",
      "rot_error: 0.09121429175138474\n",
      "rot_error: 0.09521429240703583\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 304\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     trained_agent \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ddpg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 267\u001b[0m, in \u001b[0;36mtrain_ddpg\u001b[0;34m(env, num_episodes)\u001b[0m\n\u001b[1;32m    265\u001b[0m agent\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mpush(transition)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mbuffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m    269\u001b[0m real_state \u001b[38;5;241m=\u001b[39m real_next_state\n",
      "Cell \u001b[0;32mIn[1], line 154\u001b[0m, in \u001b[0;36mDDPGAgent.update\u001b[0;34m(self, gamma, tau, device)\u001b[0m\n\u001b[1;32m    152\u001b[0m     target_param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(tau \u001b[38;5;241m*\u001b[39m param\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m tau) \u001b[38;5;241m*\u001b[39m target_param\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_param, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_target\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mparameters()):\n\u001b[0;32m--> 154\u001b[0m     target_param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(\u001b[43mtau\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m tau) \u001b[38;5;241m*\u001b[39m target_param\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from rototransl_env import TrackingEnv\n",
    "import random\n",
    "from collections import deque\n",
    "import datetime\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "NUM_NEURONS = 512   #256\n",
    "LR_ACTOR = 0.0008\n",
    "LR_CRITIC = 0.0008\n",
    "GAMMA = 0.99\n",
    "TAU = 0.005\n",
    "EARLY_STOPPING_EPISODES = 30\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = f\"PROVA{now}\"\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(NUM_NEURONS, NUM_NEURONS)\n",
    "        self.fc3 = nn.Linear(NUM_NEURONS, action_dim)\n",
    "        nn.init.uniform_(self.fc3.weight, -3e-3, 3e-3)\n",
    "        nn.init.uniform_(self.fc3.bias, -3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        if state.dim() == 1:\n",
    "            state = state.unsqueeze(0)\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        action = self.fc3(x)\n",
    "        action_xy = torch.tanh(action[:, :2]) * 5.0\n",
    "        action_rot = torch.tanh(action[:, 2:3])\n",
    "        return torch.cat([action_xy, action_rot], dim=1).squeeze(0)\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(NUM_NEURONS, NUM_NEURONS)\n",
    "        self.fc3 = nn.Linear(NUM_NEURONS, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.relu(self.fc3(x))\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "class DDPGAgent(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(DDPGAgent, self).__init__()\n",
    "        self.actor = PolicyNet(state_dim, action_dim)\n",
    "        self.actor_target = PolicyNet(state_dim, action_dim)\n",
    "        self.critic = QNet(state_dim, action_dim)\n",
    "        self.critic_target = QNet(state_dim, action_dim)\n",
    "        self.optimizer_actor = optim.Adam(self.actor.parameters(), lr=LR_ACTOR)\n",
    "        self.optimizer_critic = optim.Adam(self.critic.parameters(), lr=LR_CRITIC)\n",
    "        self.buffer = ReplayBuffer(50000) #statico e dinamico rumoroso\n",
    "        #self.buffer = ReplayBuffer(20000) #dinamico\n",
    "        self.batch_size = 128\n",
    "        self.noise_std = 1.0 #0.5\n",
    "        self.min_noise_std = 0.05 #0.01\n",
    "        self.noise_decay = 0.9995 #0.999\n",
    "\n",
    "    def reward_function(self, state, action, next_state, tolerance_transl, tolerance_rot, rimbalzato):\n",
    "        pos = state[:2]\n",
    "        target = state[3:5]              # target(t)\n",
    "        next_pos = next_state[:2]        # agent(t+1)\n",
    "\n",
    "        to_target = F.normalize(target - pos, dim=0)\n",
    "        action_dir = F.normalize(action[:2], dim=0)\n",
    "        direction_reward = torch.dot(action_dir, to_target)\n",
    "        direction_penalty = 1.0 - direction_reward\n",
    "\n",
    "        rot_error = torch.abs(next_state[2] - state[5])\n",
    "        print(f\"rot_error: {rot_error.item()}\")\n",
    "\n",
    "        \n",
    "        #reward = - 5 * direction_penalty - 5 * rot_error\n",
    "\n",
    "        reward = - 3 * rot_error\n",
    "\n",
    "        #if torch.norm(next_state[:2] - state[3:5]) < tolerance_transl and torch.norm(next_state[2] - state[5]) < tolerance_rot:\n",
    "        #    reward += 100\n",
    "        \n",
    "        #if torch.norm(next_state[:2] - state[3:5]) < tolerance_transl:\n",
    "        #    reward += 5\n",
    "\n",
    "        if torch.norm(next_state[2] - state[5]) < tolerance_rot:\n",
    "            reward += 100   #5\n",
    "\n",
    "        if rimbalzato:\n",
    "            reward -= 100\n",
    "        \n",
    "        return reward - 1\n",
    "\n",
    "    def update(self, gamma=GAMMA, tau=TAU, device='cpu'):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return\n",
    "        transitions = random.sample(self.buffer.buffer, self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*transitions)\n",
    "        states = torch.FloatTensor(np.array(states)).to(device)\n",
    "        actions = torch.FloatTensor(np.array(actions)).to(device)\n",
    "        rewards = torch.FloatTensor(np.array(rewards)).unsqueeze(1).to(device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(device)\n",
    "        dones = torch.FloatTensor(np.array(dones)).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_actions = self.actor_target(next_states)\n",
    "            target_Q = self.critic_target(next_states, next_actions)\n",
    "            y = rewards + gamma * target_Q * (1 - dones)\n",
    "\n",
    "        current_Q = self.critic(states, actions)\n",
    "        critic_loss = F.mse_loss(current_Q, y)\n",
    "\n",
    "        self.optimizer_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.optimizer_critic.step()\n",
    "\n",
    "        actor_loss = -self.critic(states, self.actor(states)).mean()\n",
    "        self.optimizer_actor.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.optimizer_actor.step()\n",
    "\n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)\n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)\n",
    "\n",
    "def save_checkpoint(agent, episode):\n",
    "    path = os.path.join(RUN_DIR, f\"checkpoint_ep{episode}.pth\")\n",
    "    torch.save({\n",
    "        'actor_state_dict': agent.actor.state_dict(),\n",
    "        'critic_state_dict': agent.critic.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def plot_and_save(rewards, successes):\n",
    "    plt.figure()\n",
    "    plt.plot(rewards, label='Total Reward')\n",
    "    plt.plot(np.convolve(successes, np.ones(10)/10, mode='valid'), label='Success Rate (10)')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Episode')\n",
    "    plt.title('DDPG Training Progress')\n",
    "    plt.savefig(os.path.join(RUN_DIR, 'training_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_trajectory_plot(trajectory, target_trajectory, episode, tag=\"trajectory\"):\n",
    "    trajectory = np.array(trajectory)\n",
    "    target_trajectory = np.array(target_trajectory)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(trajectory[:, 0], trajectory[:, 1], label=\"Agente\", color='blue')\n",
    "    plt.plot(target_trajectory[:, 0], target_trajectory[:, 1], label=\"Target\", color='red')\n",
    "    plt.scatter(*trajectory[0], color='green', label='Start agente', s=100)\n",
    "    plt.scatter(*target_trajectory[0], color='yellow', label='Start target', s=100)\n",
    "    plt.scatter(*target_trajectory[-1], color='red', label='End agente', s=100)\n",
    "    plt.scatter(target_trajectory[-5:, 0], target_trajectory[-5:, 1], color='orange', label='Ultimi target', s=10)\n",
    "    plt.scatter(trajectory[-5:, 0], trajectory[-5:, 1], color='purple', label='Ultimi agente', s=10)\n",
    "    plt.title(f\"{tag.capitalize()} - Episodio {episode}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.axis('equal')\n",
    "    #plt.savefig(os.path.join(RUN_DIR, f\"{tag}_ep{episode}.png\"))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def train_ddpg(env=None, num_episodes=10001):\n",
    "    if env is None:\n",
    "        env = TrackingEnv()\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    print(state_dim)\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    print(action_dim)\n",
    "    agent = DDPGAgent(state_dim, action_dim)\n",
    "    reward_history, success_history = [], []\n",
    "    counter = 0\n",
    "    tolerance_transl = 0.02\n",
    "    tolerance_rot = 0.00001\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        real_state = torch.tensor(state, dtype=torch.float32)\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "\n",
    "        #state = state.clone()\n",
    "        #state[2:4] += torch.normal(mean=0.0, std=0.005, size=(2,), device=state.device)\n",
    "\n",
    "        agent.noise_std = max(agent.min_noise_std, agent.noise_std * agent.noise_decay)     # Exploration\n",
    "        trajectory, target_trajectory = [], []\n",
    "        attached_counter = 0\n",
    "        total_attached_counter = 0\n",
    "\n",
    "        while not done:\n",
    "            trajectory.append(state[:2].detach().numpy())\n",
    "            target_trajectory.append(state[3:5].detach().numpy())\n",
    "            action = agent.actor(state).detach().numpy()\n",
    "            #print(f\"action: {action}\")\n",
    "            noise = np.random.normal(0, agent.noise_std, size=action.shape)\n",
    "            noisy_action = action + noise   # Exploration\n",
    "            noisy_action = np.clip(noisy_action, env.action_space.low, env.action_space.high)\n",
    "            action_tensor = torch.tensor(noisy_action, dtype=torch.float32)\n",
    "\n",
    "            next_state, _, done, truncated, _, rimbalzato = env.step(noisy_action)\n",
    "\n",
    "            real_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "            next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "            \n",
    "\n",
    "            #next_state = next_state.clone()\n",
    "            #next_state[2:4] += torch.normal(mean=0.0, std=0.005, size=(2,), device=next_state.device)\n",
    "\n",
    "            if torch.norm(real_next_state[:2] - real_state[3:5]) < tolerance_transl:\n",
    "                print(\"RAGGIUNTO TARGET, episodio:\", episode)\n",
    "\n",
    "            if torch.norm(real_next_state[2] - real_state[5]) < tolerance_rot:\n",
    "                print(\"RAGGIUNTO TARGET ROTAZIONE, episodio:\", episode)\n",
    "\n",
    "\n",
    "            #if torch.norm(real_next_state[:2] - real_state[3:5]) < tolerance_transl and torch.norm(real_next_state[2] - real_state[5]) < tolerance_rot:\n",
    "            if torch.norm(real_next_state[2] - real_state[5]) < tolerance_rot:\n",
    "                total_attached_counter += 1\n",
    "                attached_counter += 1\n",
    "            else:\n",
    "                attached_counter = 0\n",
    "\n",
    "            reward = agent.reward_function(real_state, action_tensor, real_next_state, tolerance_transl, tolerance_rot, rimbalzato)\n",
    "\n",
    "            if attached_counter == 1 or truncated:\n",
    "                done = True\n",
    "\n",
    "            #condition = torch.norm(real_next_state[:2] - real_state[3:5]) > tolerance_transl or torch.norm(real_next_state[2] - real_state[5]) > tolerance_rot\n",
    "            #if attached_counter > 20 or truncated or (total_attached_counter > 0 and condition):\n",
    "            #    done = True\n",
    "            \n",
    "            transition = (state.numpy(), action_tensor.numpy(), reward, next_state.numpy(), float(done))\n",
    "            agent.buffer.push(transition)\n",
    "            if len(agent.buffer) > 1000:\n",
    "                agent.update()\n",
    "            state = next_state\n",
    "            real_state = real_next_state\n",
    "            total_reward += reward\n",
    "\n",
    "\n",
    "        if attached_counter == 1:   #> 20:\n",
    "            save_trajectory_plot(trajectory, target_trajectory, episode, tag=\"success\")\n",
    "            counter += 1\n",
    "            success_history.append(1)\n",
    "            if counter % 100 == 0:\n",
    "                save_trajectory_plot(trajectory, target_trajectory, episode, tag=\"success\")\n",
    "        else:\n",
    "            success_history.append(0)\n",
    "\n",
    "        reward_history.append(total_reward)\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"Episode {episode}, Reward: {total_reward:.2f}, Attached_counter: {attached_counter}, Total attached counter: {total_attached_counter}, Successes: {counter}\")\n",
    "        if episode % CHECKPOINT_INTERVAL == 0 and episode > 0:\n",
    "            save_checkpoint(agent, episode)\n",
    "        if episode % 50 == 0 and episode > 0:\n",
    "            save_trajectory_plot(trajectory, target_trajectory, episode)\n",
    "\n",
    "        if len(reward_history) > EARLY_STOPPING_EPISODES and np.mean(reward_history[-EARLY_STOPPING_EPISODES:]) > 2000:\n",
    "           print(f\"Early stopping at episode {episode}\")\n",
    "           save_checkpoint(agent, episode)\n",
    "           save_trajectory_plot(trajectory, target_trajectory, episode)\n",
    "           break\n",
    "\n",
    "    np.save(os.path.join(RUN_DIR, 'rewards.npy'), reward_history)\n",
    "    np.save(os.path.join(RUN_DIR, 'successes.npy'), success_history)\n",
    "    plot_and_save(reward_history, success_history)\n",
    "    env.close()\n",
    "    return agent\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trained_agent = train_ddpg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Reward: -130.78, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "Episode 10, Reward: 1057.04, Attached_counter: 0, Total attached counter: 11, Successes: 0\n",
      "Episode 20, Reward: 83.84, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 30, Reward: -130.59, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "Episode 40, Reward: -136.89, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "Episode 50, Reward: 158.24, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 60, Reward: -125.88, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "Episode 70, Reward: 483.35, Attached_counter: 0, Total attached counter: 5, Successes: 0\n",
      "Episode 80, Reward: 95.86, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 90, Reward: 284.20, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 100, Reward: -130.62, Attached_counter: 0, Total attached counter: 0, Successes: 0\n",
      "Episode 110, Reward: 182.69, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 120, Reward: 131.75, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 130, Reward: 442.86, Attached_counter: 0, Total attached counter: 5, Successes: 0\n",
      "Episode 140, Reward: 59.87, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 150, Reward: 67.24, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 160, Reward: 286.13, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 170, Reward: 290.25, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 180, Reward: 383.26, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 190, Reward: 196.92, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 200, Reward: 194.80, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 210, Reward: 186.02, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 220, Reward: 337.47, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 230, Reward: 76.92, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 240, Reward: 75.20, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 250, Reward: 90.54, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 260, Reward: 86.15, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 270, Reward: 62.43, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 280, Reward: 249.27, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 290, Reward: 169.54, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 300, Reward: 97.96, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 310, Reward: 60.31, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 320, Reward: 48.45, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 330, Reward: 194.73, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 340, Reward: 84.55, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 350, Reward: 125.71, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 360, Reward: 276.68, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 370, Reward: 676.96, Attached_counter: 0, Total attached counter: 7, Successes: 0\n",
      "Episode 380, Reward: 388.49, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 390, Reward: 283.06, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 400, Reward: 71.10, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 410, Reward: 186.03, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 420, Reward: 72.36, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 430, Reward: 88.07, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 440, Reward: 52.52, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 450, Reward: 196.92, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 460, Reward: 53.67, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 470, Reward: 177.72, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 480, Reward: 191.17, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 490, Reward: 157.08, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 500, Reward: 92.62, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 510, Reward: 196.92, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 520, Reward: 352.38, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 530, Reward: 56.94, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 540, Reward: 266.96, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 550, Reward: 286.85, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 560, Reward: 96.88, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 570, Reward: 272.93, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 580, Reward: 190.23, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 590, Reward: 65.14, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 600, Reward: 394.91, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 610, Reward: 292.67, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 620, Reward: 294.87, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 630, Reward: 267.89, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 640, Reward: 89.83, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 650, Reward: 374.40, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 660, Reward: 269.10, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 670, Reward: 267.51, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 680, Reward: 295.91, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 690, Reward: 392.77, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 700, Reward: 63.50, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 710, Reward: 886.48, Attached_counter: 0, Total attached counter: 9, Successes: 0\n",
      "Episode 720, Reward: 162.36, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 730, Reward: 776.21, Attached_counter: 0, Total attached counter: 8, Successes: 0\n",
      "Episode 740, Reward: 181.79, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 750, Reward: 293.77, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 760, Reward: 290.40, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 770, Reward: 73.74, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 780, Reward: 192.55, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 790, Reward: 92.18, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 800, Reward: 368.92, Attached_counter: 0, Total attached counter: 4, Successes: 0\n",
      "Episode 810, Reward: 274.85, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 820, Reward: 982.31, Attached_counter: 0, Total attached counter: 10, Successes: 0\n",
      "Episode 830, Reward: 70.66, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 840, Reward: 95.79, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 850, Reward: 184.78, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 860, Reward: 162.96, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 870, Reward: 165.85, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 880, Reward: 292.75, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 890, Reward: 592.86, Attached_counter: 0, Total attached counter: 6, Successes: 0\n",
      "Episode 900, Reward: 78.87, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 910, Reward: 88.48, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 920, Reward: 289.84, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 930, Reward: 268.07, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 940, Reward: 96.92, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 950, Reward: 260.39, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 960, Reward: 46.89, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 970, Reward: 54.56, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 980, Reward: 488.37, Attached_counter: 0, Total attached counter: 5, Successes: 0\n",
      "Episode 990, Reward: 96.92, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 1000, Reward: 162.06, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 1010, Reward: 953.16, Attached_counter: 0, Total attached counter: 10, Successes: 0\n",
      "Episode 1020, Reward: 179.44, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 1030, Reward: 80.78, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 1040, Reward: 72.75, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 1050, Reward: 295.92, Attached_counter: 0, Total attached counter: 3, Successes: 0\n",
      "Episode 1060, Reward: 544.79, Attached_counter: 0, Total attached counter: 6, Successes: 0\n",
      "Episode 1070, Reward: 68.41, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 1080, Reward: 196.91, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 1090, Reward: 77.35, Attached_counter: 0, Total attached counter: 1, Successes: 0\n",
      "Episode 1100, Reward: 186.21, Attached_counter: 0, Total attached counter: 2, Successes: 0\n",
      "Episode 1110, Reward: 150.31, Attached_counter: 0, Total attached counter: 2, Successes: 1\n",
      "Episode 1120, Reward: 191.97, Attached_counter: 0, Total attached counter: 2, Successes: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 257\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 257\u001b[0m     trained_agent \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ddpg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 222\u001b[0m, in \u001b[0;36mtrain_ddpg\u001b[0;34m(env, num_episodes)\u001b[0m\n\u001b[1;32m    220\u001b[0m agent\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mpush(transition)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mbuffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m    224\u001b[0m real_state \u001b[38;5;241m=\u001b[39m real_next_state\n",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m, in \u001b[0;36mDDPGAgent.update\u001b[0;34m(self, gamma, tau, device)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_critic\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    116\u001b[0m critic_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_critic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(states))\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_actor\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mujoco-env/lib/python3.9/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mujoco-env/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mujoco-env/lib/python3.9/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mujoco-env/lib/python3.9/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mujoco-env/lib/python3.9/site-packages/torch/optim/adam.py:392\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    391\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 392\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    395\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from env_rot import TrackingEnv\n",
    "import random\n",
    "from collections import deque\n",
    "import datetime\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "NUM_NEURONS = 128\n",
    "LR_ACTOR = 0.001\n",
    "LR_CRITIC = 0.0008\n",
    "GAMMA = 0.99\n",
    "TAU = 0.005\n",
    "EARLY_STOPPING_EPISODES = 30\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = f\"PROVA{now}\"\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(NUM_NEURONS, NUM_NEURONS)\n",
    "        self.fc3 = nn.Linear(NUM_NEURONS, action_dim)\n",
    "        nn.init.uniform_(self.fc3.weight, -3e-3, 3e-3)\n",
    "        nn.init.uniform_(self.fc3.bias, -3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        action = torch.tanh(self.fc3(x))\n",
    "        return action\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(NUM_NEURONS, NUM_NEURONS)\n",
    "        self.fc3 = nn.Linear(NUM_NEURONS, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "class DDPGAgent(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(DDPGAgent, self).__init__()\n",
    "        self.actor = PolicyNet(state_dim, action_dim)\n",
    "        self.actor_target = PolicyNet(state_dim, action_dim)\n",
    "        self.critic = QNet(state_dim, action_dim)\n",
    "        self.critic_target = QNet(state_dim, action_dim)\n",
    "        self.optimizer_actor = optim.Adam(self.actor.parameters(), lr=LR_ACTOR)\n",
    "        self.optimizer_critic = optim.Adam(self.critic.parameters(), lr=LR_CRITIC)\n",
    "        self.buffer = ReplayBuffer(50000) \n",
    "        self.batch_size = 128\n",
    "        self.noise_std = 0.5\n",
    "        self.min_noise_std = 0.01\n",
    "        self.noise_decay = 0.999\n",
    "\n",
    "    def reward_function(self, state, action, next_state, step, tolerance):\n",
    "       \n",
    "        rot_error = torch.norm(state[1]-next_state[0])\n",
    "        reward = - rot_error.item() * 3\n",
    "\n",
    "        if torch.norm(next_state[0] - state[1]) < tolerance:\n",
    "            reward += 100\n",
    "        \n",
    "        return reward - 1\n",
    "\n",
    "    def update(self, gamma=GAMMA, tau=TAU, device='cpu'):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return\n",
    "        transitions = random.sample(self.buffer.buffer, self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*transitions)\n",
    "        states = torch.FloatTensor(np.array(states)).to(device)\n",
    "        actions = torch.FloatTensor(np.array(actions)).to(device)\n",
    "        rewards = torch.FloatTensor(np.array(rewards)).unsqueeze(1).to(device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(device)\n",
    "        dones = torch.FloatTensor(np.array(dones)).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_actions = self.actor_target(next_states)\n",
    "            target_Q = self.critic_target(next_states, next_actions)\n",
    "            y = rewards + gamma * target_Q * (1 - dones)\n",
    "\n",
    "        current_Q = self.critic(states, actions)\n",
    "        critic_loss = F.mse_loss(current_Q, y)\n",
    "\n",
    "        self.optimizer_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.optimizer_critic.step()\n",
    "\n",
    "        actor_loss = -self.critic(states, self.actor(states)).mean()\n",
    "        self.optimizer_actor.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.optimizer_actor.step()\n",
    "\n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)\n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)\n",
    "\n",
    "def save_checkpoint(agent, episode):\n",
    "    path = os.path.join(RUN_DIR, f\"checkpoint_ep{episode}.pth\")\n",
    "    torch.save({\n",
    "        'actor_state_dict': agent.actor.state_dict(),\n",
    "        'critic_state_dict': agent.critic.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def plot_and_save(rewards, successes):\n",
    "    plt.figure()\n",
    "    plt.plot(rewards, label='Total Reward')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Episode')\n",
    "    plt.title('DDPG Training Progress')\n",
    "    plt.savefig(os.path.join(RUN_DIR, 'training_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_trajectory_plot(trajectory, target_trajectory, episode, tag=\"trajectory\"):\n",
    "    trajectory = np.array(trajectory)\n",
    "    target_trajectory = np.array(target_trajectory)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(trajectory, label=\"Agente\", color='blue')\n",
    "    plt.plot(target_trajectory, label=\"Target\", color='red')\n",
    "    plt.scatter(0, trajectory[0], color='green', label='Start agente', s=60)\n",
    "    plt.scatter(0, target_trajectory[0], color='yellow', label='Start target', s=60)\n",
    "    plt.scatter(len(target_trajectory) - 1, target_trajectory[-1], color='red', label='End target', s=60)\n",
    "    plt.scatter(len(trajectory) - 1, trajectory[-1], color='purple', label='End agente', s=60)\n",
    "    plt.title(f\"{tag.capitalize()} - Episodio {episode}\")\n",
    "    plt.xlabel(\"Step temporale\")\n",
    "    plt.ylabel(\"Valore (es. angolo)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RUN_DIR, f\"{tag}_ep{episode}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def train_ddpg(env=None, num_episodes=10001):\n",
    "    if env is None:\n",
    "        env = TrackingEnv()\n",
    "    state_dim = 2\n",
    "    action_dim = 1\n",
    "    agent = DDPGAgent(state_dim, action_dim)\n",
    "    reward_history, success_history = [], []\n",
    "    counter = 0\n",
    "    tolerance = 0.01\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        real_state = torch.tensor(state, dtype=torch.float32)\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "\n",
    "        # state = state.clone()\n",
    "        # state[2:4] += torch.normal(mean=0.0, std=0.005, size=(2,), device=state.device)\n",
    "\n",
    "        agent.noise_std = max(agent.min_noise_std, agent.noise_std * agent.noise_decay)     # Exploration\n",
    "        trajectory, target_trajectory = [], []\n",
    "        attached_counter = 0\n",
    "        total_attached_counter = 0\n",
    "\n",
    "        while not done:\n",
    "            trajectory.append(state[0].detach().numpy())\n",
    "            target_trajectory.append(state[1].detach().numpy())\n",
    "            action = agent.actor(state).detach().numpy()#, training=True).detach().numpy()\n",
    "            noise = np.random.normal(0, agent.noise_std, size=action.shape)\n",
    "            noisy_action = action + noise   # Exploration\n",
    "            noisy_action = np.clip(noisy_action, env.action_space.low, env.action_space.high)\n",
    "            action_tensor = torch.tensor(noisy_action, dtype=torch.float32)\n",
    "\n",
    "            next_state, _, done, truncated, _ = env.step(noisy_action)\n",
    "            real_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "            next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "            \n",
    "\n",
    "            # next_state = next_state.clone()\n",
    "            # next_state[2:4] += torch.normal(mean=0.0, std=0.005, size=(2,), device=next_state.device)\n",
    "\n",
    "\n",
    "            if torch.norm(real_next_state[0] - real_state[1]) < tolerance:\n",
    "                total_attached_counter += 1\n",
    "                attached_counter += 1\n",
    "            else:\n",
    "                attached_counter = 0\n",
    "\n",
    "            reward = agent.reward_function(real_state, action_tensor, real_next_state, 0, tolerance)\n",
    "\n",
    "            if attached_counter > 20 or truncated or (total_attached_counter > 0 and torch.norm(real_next_state[0] - real_state[1]) > tolerance):\n",
    "                done = True\n",
    "            \n",
    "            transition = (state.numpy(), action_tensor.numpy(), reward, next_state.numpy(), float(done))\n",
    "            agent.buffer.push(transition)\n",
    "            if len(agent.buffer) > 1000:\n",
    "                agent.update()\n",
    "            state = next_state\n",
    "            real_state = real_next_state\n",
    "            total_reward += reward\n",
    "\n",
    "        if attached_counter > 20:\n",
    "            counter += 1\n",
    "            success_history.append(1)\n",
    "            if counter % 100 == 0:\n",
    "                save_trajectory_plot(trajectory, target_trajectory, episode, tag=\"success\")\n",
    "        else:\n",
    "            success_history.append(0)\n",
    "\n",
    "        reward_history.append(total_reward)\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"Episode {episode}, Reward: {total_reward:.2f}, Attached_counter: {attached_counter}, Total attached counter: {total_attached_counter}, Successes: {counter}\")\n",
    "        if episode % CHECKPOINT_INTERVAL == 0 and episode > 0:\n",
    "            save_checkpoint(agent, episode)\n",
    "        if episode % 50 == 0 and episode > 0:\n",
    "            save_trajectory_plot(trajectory, target_trajectory, episode)\n",
    "\n",
    "        if len(reward_history) > EARLY_STOPPING_EPISODES and np.mean(reward_history[-EARLY_STOPPING_EPISODES:]) > 2000:\n",
    "           print(f\"Early stopping at episode {episode}\")\n",
    "           save_checkpoint(agent, episode)\n",
    "           save_trajectory_plot(trajectory, target_trajectory, episode)\n",
    "           break\n",
    "\n",
    "    np.save(os.path.join(RUN_DIR, 'rewards.npy'), reward_history)\n",
    "    np.save(os.path.join(RUN_DIR, 'successes.npy'), success_history)\n",
    "    plot_and_save(reward_history, success_history)\n",
    "    env.close()\n",
    "    return agent\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trained_agent = train_ddpg()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
    "policy_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVMAAAAAAAAACMHnN0YWJsZV9iYXNlbGluZXMzLnNhYy5wb2xpY2llc5SMCVNBQ1BvbGljeZSTlC4=",
        "__module__": "stable_baselines3.sac.policies",
        "__annotations__": "{'actor': <class 'stable_baselines3.sac.policies.Actor'>, 'critic': <class 'stable_baselines3.common.policies.ContinuousCritic'>, 'critic_target': <class 'stable_baselines3.common.policies.ContinuousCritic'>}",
        "__doc__": "\n    Policy class (with both actor and critic) for SAC.\n\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param use_sde: Whether to use State Dependent Exploration or not\n    :param log_std_init: Initial value for the log standard deviation\n    :param use_expln: Use ``expln()`` function instead of ``exp()`` when using gSDE to ensure\n        a positive standard deviation (cf paper). It allows to keep variance\n        above zero and prevent it from growing too fast. In practice, ``exp()`` is usually enough.\n    :param clip_mean: Clip the mean output when using gSDE to avoid numerical instability.\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments\n        to pass to the features extractor.\n    :param normalize_images: Whether to normalize images or not,\n         dividing by 255.0 (True by default)\n    :param optimizer_class: The optimizer to use,\n        ``th.optim.Adam`` by default\n    :param optimizer_kwargs: Additional keyword arguments,\n        excluding the learning rate, to pass to the optimizer\n    :param n_critics: Number of critic networks to create.\n    :param share_features_extractor: Whether to share or not the features extractor\n        between the actor and the critic (this saves computation time)\n    ",
        "__init__": "<function SACPolicy.__init__ at 0x7f5fbe81c5e0>",
        "_build": "<function SACPolicy._build at 0x7f5fbe81c670>",
        "_get_constructor_parameters": "<function SACPolicy._get_constructor_parameters at 0x7f5fbe81c700>",
        "reset_noise": "<function SACPolicy.reset_noise at 0x7f5fbe81c790>",
        "make_actor": "<function SACPolicy.make_actor at 0x7f5fbe81c820>",
        "make_critic": "<function SACPolicy.make_critic at 0x7f5fbe81c8b0>",
        "forward": "<function SACPolicy.forward at 0x7f5fbe81c940>",
        "_predict": "<function SACPolicy._predict at 0x7f5fbe81c9d0>",
        "set_training_mode": "<function SACPolicy.set_training_mode at 0x7f5fbe81ca60>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x7f5fbe807700>"
    },
    "verbose": 1,
    "policy_kwargs": {
        "use_sde": false
    },
    "num_timesteps": 100000,
    "_total_timesteps": 100000,
    "_num_timesteps_at_start": 0,
    "seed": null,
    "action_noise": null,
    "start_time": 1749316776965602631,
    "learning_rate": 0.0003,
    "tensorboard_log": null,
    "_last_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVfgAAAAAAAACME251bXB5Ll9jb3JlLm51bWVyaWOUjAtfZnJvbWJ1ZmZlcpSTlCiWCAAAAAAAAABw1pE+wC2ovpSMBW51bXB5lIwFZHR5cGWUk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGJLAUsChpSMAUOUdJRSlC4="
    },
    "_last_episode_starts": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVdQAAAAAAAACME251bXB5Ll9jb3JlLm51bWVyaWOUjAtfZnJvbWJ1ZmZlcpSTlCiWAQAAAAAAAAABlIwFbnVtcHmUjAVkdHlwZZSTlIwCYjGUiYiHlFKUKEsDjAF8lE5OTkr/////Sv////9LAHSUYksBhZSMAUOUdJRSlC4="
    },
    "_last_original_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVfgAAAAAAAACME251bXB5Ll9jb3JlLm51bWVyaWOUjAtfZnJvbWJ1ZmZlcpSTlCiWCAAAAAAAAAA6O9G9fD2bvZSMBW51bXB5lIwFZHR5cGWUk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGJLAUsChpSMAUOUdJRSlC4="
    },
    "_episode_num": 1000,
    "use_sde": false,
    "sde_sample_freq": -1,
    "_current_progress_remaining": 0.0,
    "_stats_window_size": 100,
    "ep_info_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "gAWVIAAAAAAAAACMC2NvbGxlY3Rpb25zlIwFZGVxdWWUk5QpS2SGlFKULg=="
    },
    "ep_success_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "gAWVIAAAAAAAAACMC2NvbGxlY3Rpb25zlIwFZGVxdWWUk5QpS2SGlFKULg=="
    },
    "_n_updates": 99900,
    "observation_space": {
        ":type:": "<class 'gymnasium.spaces.box.Box'>",
        ":serialized:": "gAWVlgEAAAAAAACMFGd5bW5hc2l1bS5zcGFjZXMuYm94lIwDQm94lJOUKYGUfZQojAVkdHlwZZSMBW51bXB5lIwFZHR5cGWUk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGKMDWJvdW5kZWRfYmVsb3eUjBNudW1weS5fY29yZS5udW1lcmljlIwLX2Zyb21idWZmZXKUk5QolgIAAAAAAAAAAQGUaAiMAmIxlImIh5RSlChLA4wBfJROTk5K/////0r/////SwB0lGJLAoWUjAFDlHSUUpSMDWJvdW5kZWRfYWJvdmWUaBEolgIAAAAAAAAAAQGUaBVLAoWUaBl0lFKUjAZfc2hhcGWUSwKFlIwDbG93lGgRKJYIAAAAAAAAAMP1SMDD9UjAlGgLSwKFlGgZdJRSlIwEaGlnaJRoESiWCAAAAAAAAADD9UhAw/VIQJRoC0sChZRoGXSUUpSMCGxvd19yZXBylIwFLTMuMTSUjAloaWdoX3JlcHKUjAQzLjE0lIwKX25wX3JhbmRvbZROdWIu",
        "dtype": "float32",
        "bounded_below": "[ True  True]",
        "bounded_above": "[ True  True]",
        "_shape": [
            2
        ],
        "low": "[-3.14 -3.14]",
        "high": "[3.14 3.14]",
        "low_repr": "-3.14",
        "high_repr": "3.14",
        "_np_random": null
    },
    "action_space": {
        ":type:": "<class 'gymnasium.spaces.box.Box'>",
        ":serialized:": "gAWVLAMAAAAAAACMFGd5bW5hc2l1bS5zcGFjZXMuYm94lIwDQm94lJOUKYGUfZQojAVkdHlwZZSMBW51bXB5lIwFZHR5cGWUk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGKMDWJvdW5kZWRfYmVsb3eUjBNudW1weS5fY29yZS5udW1lcmljlIwLX2Zyb21idWZmZXKUk5QolgEAAAAAAAAAAZRoCIwCYjGUiYiHlFKUKEsDjAF8lE5OTkr/////Sv////9LAHSUYksBhZSMAUOUdJRSlIwNYm91bmRlZF9hYm92ZZRoESiWAQAAAAAAAAABlGgVSwGFlGgZdJRSlIwGX3NoYXBllEsBhZSMA2xvd5RoESiWBAAAAAAAAAAAAKDAlGgLSwGFlGgZdJRSlIwEaGlnaJRoESiWBAAAAAAAAAAAAKBAlGgLSwGFlGgZdJRSlIwIbG93X3JlcHKUjAQtNS4wlIwJaGlnaF9yZXBylIwDNS4wlIwKX25wX3JhbmRvbZSMFG51bXB5LnJhbmRvbS5fcGlja2xllIwQX19nZW5lcmF0b3JfY3RvcpSTlGgyjBRfX2JpdF9nZW5lcmF0b3JfY3RvcpSTlIwTbnVtcHkucmFuZG9tLl9wY2c2NJSMBVBDRzY0lJOUhZRSlH2UKIwNYml0X2dlbmVyYXRvcpSMBVBDRzY0lIwFc3RhdGWUfZQoaD+KEIOn172Wm+ocH1OSSEbyt0aMA2luY5SKEWsYFO9WkzcR7m0p95z5LuwAdYwKaGFzX3VpbnQzMpRLAIwIdWludGVnZXKUSwB1jBpudW1weS5yYW5kb20uYml0X2dlbmVyYXRvcpSMG19fcHl4X3VucGlja2xlX1NlZWRTZXF1ZW5jZZSTlGhEjAxTZWVkU2VxdWVuY2WUk5RKIqLqA06HlFKUKIoQ2S3KNwhoT2huJggZRwfte0sAaBEolhAAAAAAAAAABlcNJvydULZ6IhEIIVJklZRoCIwCdTSUiYiHlFKUKEsDaAxOTk5K/////0r/////SwB0lGJLBIWUaBl0lFKUSwQpdJRihpRihZRSlHViLg==",
        "dtype": "float32",
        "bounded_below": "[ True]",
        "bounded_above": "[ True]",
        "_shape": [
            1
        ],
        "low": "[-5.]",
        "high": "[5.]",
        "low_repr": "-5.0",
        "high_repr": "5.0",
        "_np_random": "Generator(PCG64)"
    },
    "n_envs": 1,
    "buffer_size": 1000000,
    "batch_size": 256,
    "learning_starts": 100,
    "tau": 0.005,
    "gamma": 0.99,
    "gradient_steps": 1,
    "optimize_memory_usage": false,
    "replay_buffer_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVNQAAAAAAAACMIHN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi5idWZmZXJzlIwMUmVwbGF5QnVmZmVylJOULg==",
        "__module__": "stable_baselines3.common.buffers",
        "__annotations__": "{'observations': <class 'numpy.ndarray'>, 'next_observations': <class 'numpy.ndarray'>, 'actions': <class 'numpy.ndarray'>, 'rewards': <class 'numpy.ndarray'>, 'dones': <class 'numpy.ndarray'>, 'timeouts': <class 'numpy.ndarray'>}",
        "__doc__": "\n    Replay buffer used in off-policy algorithms like SAC/TD3.\n\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param device: PyTorch device\n    :param n_envs: Number of parallel environments\n    :param optimize_memory_usage: Enable a memory efficient variant\n        of the replay buffer which reduces by almost a factor two the memory used,\n        at a cost of more complexity.\n        See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n        and https://github.com/DLR-RM/stable-baselines3/pull/28#issuecomment-637559274\n        Cannot be used in combination with handle_timeout_termination.\n    :param handle_timeout_termination: Handle timeout termination (due to timelimit)\n        separately and treat the task as infinite horizon task.\n        https://github.com/DLR-RM/stable-baselines3/issues/284\n    ",
        "__init__": "<function ReplayBuffer.__init__ at 0x7f5fbeacf6d0>",
        "add": "<function ReplayBuffer.add at 0x7f5fbeacf760>",
        "sample": "<function ReplayBuffer.sample at 0x7f5fbeacf7f0>",
        "_get_samples": "<function ReplayBuffer._get_samples at 0x7f5fbeacf880>",
        "_maybe_cast_dtype": "<staticmethod(<function ReplayBuffer._maybe_cast_dtype at 0x7f5fbeacf910>)>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x7f5fbfdad8c0>"
    },
    "replay_buffer_kwargs": {},
    "train_freq": {
        ":type:": "<class 'stable_baselines3.common.type_aliases.TrainFreq'>",
        ":serialized:": "gAWVYQAAAAAAAACMJXN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi50eXBlX2FsaWFzZXOUjAlUcmFpbkZyZXGUk5RLAWgAjBJUcmFpbkZyZXF1ZW5jeVVuaXSUk5SMBHN0ZXCUhZRSlIaUgZQu"
    },
    "use_sde_at_warmup": false,
    "target_entropy": -1.0,
    "ent_coef": "auto",
    "target_update_interval": 1,
    "lr_schedule": {
        ":type:": "<class 'function'>",
        ":serialized:": "gAWV1QMAAAAAAACMF2Nsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX21ha2VfZnVuY3Rpb26Uk5QoaACMDV9idWlsdGluX3R5cGWUk5SMCENvZGVUeXBllIWUUpQoSwFLAEsASwFLA0sTQwx0AIgAfACDAYMBUwCUToWUjAVmbG9hdJSFlIwScHJvZ3Jlc3NfcmVtYWluaW5nlIWUjGsvdS9kc3NjL2V6YXBwaWEvbWluaWNvbmRhMy9lbnZzL3RyYWNraW5nX2Vudi9saWIvcHl0aG9uMy4xMC9zaXRlLXBhY2thZ2VzL3N0YWJsZV9iYXNlbGluZXMzL2NvbW1vbi91dGlscy5weZSMCDxsYW1iZGE+lEtiQwIMAJSMDnZhbHVlX3NjaGVkdWxllIWUKXSUUpR9lCiMC19fcGFja2FnZV9flIwYc3RhYmxlX2Jhc2VsaW5lczMuY29tbW9ulIwIX19uYW1lX1+UjB5zdGFibGVfYmFzZWxpbmVzMy5jb21tb24udXRpbHOUjAhfX2ZpbGVfX5SMay91L2Rzc2MvZXphcHBpYS9taW5pY29uZGEzL2VudnMvdHJhY2tpbmdfZW52L2xpYi9weXRob24zLjEwL3NpdGUtcGFja2FnZXMvc3RhYmxlX2Jhc2VsaW5lczMvY29tbW9uL3V0aWxzLnB5lHVOTmgAjBBfbWFrZV9lbXB0eV9jZWxslJOUKVKUhZR0lFKUaACMEl9mdW5jdGlvbl9zZXRzdGF0ZZSTlGghfZR9lChoGIwIPGxhbWJkYT6UjAxfX3F1YWxuYW1lX1+UjCFnZXRfc2NoZWR1bGVfZm4uPGxvY2Fscz4uPGxhbWJkYT6UjA9fX2Fubm90YXRpb25zX1+UfZSMDl9fa3dkZWZhdWx0c19flE6MDF9fZGVmYXVsdHNfX5ROjApfX21vZHVsZV9flGgZjAdfX2RvY19flE6MC19fY2xvc3VyZV9flGgAjApfbWFrZV9jZWxslJOUaAIoaAcoSwFLAEsASwFLAUsTQwSIAFMAlGgJKYwBX5SFlGgOjARmdW5jlEuGQwIEAZSMA3ZhbJSFlCl0lFKUaBVOTmgdKVKUhZR0lFKUaCNoPn2UfZQoaBiMBGZ1bmOUaCeMGWNvbnN0YW50X2ZuLjxsb2NhbHM+LmZ1bmOUaCl9lGgrTmgsTmgtaBloLk5oL2gxRz8zqSowVTJhhZRSlIWUjBdfY2xvdWRwaWNrbGVfc3VibW9kdWxlc5RdlIwLX19nbG9iYWxzX1+UfZR1hpSGUjCFlFKUhZRoR12UaEl9lHWGlIZSMC4="
    },
    "batch_norm_stats": [],
    "batch_norm_stats_target": []
}